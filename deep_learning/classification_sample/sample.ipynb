{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58e72378-69e5-4276-ba43-024ec1281e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce0e9bd3-026d-457b-91c8-20faa57a097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, TrainTest=\"train\"):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        どのデータを使うのかを記述する部分\n",
    "        \"\"\"\n",
    "        #ここではtrain/testのみのスプリットをしておき，valは別機能で外からスプリットする\n",
    "        if TrainTest == \"train\":\n",
    "            #self.img_path_list = sorted(glob.glob(\"/content/drive/MyDrive/segmentation/data/train/org/*\"))\n",
    "            self.img_path_list = sorted(glob.glob(\"/takaya_workspace/self_study/deep_learning/classification_sample/data/train/*/*\"))\n",
    "        elif TrainTest == \"test\":\n",
    "            self.img_path_list = sorted(glob.glob(\"/takaya_workspace/self_study/deep_learning/classification_sample/data/test/*/*\"))\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        データがいくつあるのかを数える\n",
    "        \"\"\"\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        データをどのような形で取り出すのか記述する\n",
    "        \"\"\"\n",
    "        image_path = self.img_path_list[index] # ファイル名\n",
    "        if \"dog\" in image_path:\n",
    "            label = np.array(0)\n",
    "        else:\n",
    "            label = np.array(1)\n",
    "        \n",
    "        img = Image.open(image_path) # ファイル名を与えて画像を取り出す\n",
    "        img = np.array(img) # 画像をnumpy形式の行列へ変換\n",
    "        img = img.transpose(2,0,1)\n",
    "        img = torch.tensor(img) # 行列をpytorchで扱える形式（tensor型）に変換する\n",
    "        img = img / 255 # 0~255までの値を0~1までの値に変換する\n",
    "        \n",
    "    \n",
    "        label = torch.tensor(label)\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3d7df68-4dd0-4ba9-a377-56e609eca229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformの定義\n",
    "from torchvision import transforms\n",
    "data_transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82b66560-4d8c-4cad-962e-bf8eec0e9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#animal_train = AnimalDataset(TrainTest=\"train\")\n",
    "#animal_test = AnimalDataset(TrainTest=\"test\")\n",
    "animal_train = datasets.ImageFolder(\"/takaya_workspace/self_study/deep_learning/classification_sample/data/train/\", data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b024107-5639-4eb1-9712-d48d8ccf4ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(animal_train) \n",
    "train_size = int(n_samples * 0.8) \n",
    "val_size = n_samples - train_size \n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(animal_train, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0dc788f-82b3-4360-a608-fe2cdd4fba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f01206ae-c940-4bc0-be10-ced9edc5b348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a781096-ec10-47f8-8754-a0a526838e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature = resnet18(pretrained=True)\n",
    "        self.fc = nn.Linear(1000, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.feature(x)\n",
    "        h = self.fc(h)\n",
    "        return h\n",
    "    \n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = torch.nn.Conv2d(3,  # チャネル入力\n",
    "#                                      60,  # チャンネル出力\n",
    "#                                      3,  # カーネルサイズ\n",
    "#                                      1,  # ストライド (デフォルトは1)\n",
    "#                                      0,  # パディング (デフォルトは0)\n",
    "#                                      )\n",
    "#         self.conv2 = torch.nn.Conv2d(60, 30, 3)\n",
    " \n",
    "#         self.pool = torch.nn.MaxPool2d(2, 2)  # カーネルサイズ, ストライド\n",
    " \n",
    "#         self.fc1 = torch.nn.Linear(87480, 500)  # 入力サイズ, 出力サイズ\n",
    "#         self.fc2 = torch.nn.Linear(500, 100)\n",
    "#         self.fc3 = torch.nn.Linear(100, 2)\n",
    " \n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.pool(x)\n",
    "#         x = x.view(x.size(0), -1)  # 1次元データに変えて全結合層へ\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0a951734-6463-48e2-96f7-41874c3ef024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1\n",
      "train_loss:tensor(0.4541, device='cuda:0')\n",
      "val_loss:tensor(0.0371, device='cuda:0')\n",
      "saved best model!\n",
      "epoch2\n",
      "train_loss:tensor(0.1903, device='cuda:0')\n",
      "val_loss:tensor(0.0288, device='cuda:0')\n",
      "saved best model!\n",
      "epoch3\n",
      "train_loss:tensor(0.1297, device='cuda:0')\n",
      "val_loss:tensor(0.3790, device='cuda:0')\n",
      "epoch4\n",
      "train_loss:tensor(0.1100, device='cuda:0')\n",
      "val_loss:tensor(0.0605, device='cuda:0')\n",
      "epoch5\n",
      "train_loss:tensor(0.2853, device='cuda:0')\n",
      "val_loss:tensor(0.3197, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import BCELoss\n",
    "import torch.optim as optim\n",
    "\n",
    "# モデルの定義\n",
    "model = resnet()\n",
    "\n",
    "# GPUを使う場合は，下記のコメントを外す\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# optimizer（勾配降下法のアルゴリズム）の準備\n",
    "optimizer = optim.RAdam(model.parameters())\n",
    "\n",
    "# 誤差関数の定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 学習ループ\n",
    "epochs = 5 #ミニバッチのサンプリングが一巡 = 1 epoch\n",
    "\n",
    "train_loss_list = [] # epoch毎のtrain_lossを保存しておくための入れ物\n",
    "val_loss_list = [] # epoch毎のvalidation_lossを保存しておくための入れ物\n",
    "\n",
    "loss_min = 100000 # validation_lossが小さくなった場合にのみモデルを保存しておくためのメモ\n",
    "\n",
    "# ここからループ開始\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss_add = 0 # 1エポック分の誤差を累積しておくための変数\n",
    "    \n",
    "    model.train() #学習モードであることを明示\n",
    "   \n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        x, t = data # ①データの読み込み\n",
    "        \n",
    "        #GPU環境で動かす際は，下記2行のコメントを外す\n",
    "        x = x.to(\"cuda\")\n",
    "        t = t.to(\"cuda\")\n",
    "        predict = model(x) # ②順伝播計算\n",
    "        \n",
    "        loss = criterion(predict, t) # ③誤差の計算\n",
    "        \n",
    "        model.zero_grad()# 誤差逆伝播法のための準備\n",
    "        loss.backward() # ④誤差逆伝播法による誤差の計算\n",
    "        \n",
    "        optimizer.step() # ⑤勾配を用いてパラメータを更新\n",
    "        \n",
    "        train_loss_add += loss.data # あとで平均を計算するために，誤差を累積しておく\n",
    "        \n",
    "    train_loss_mean = train_loss_add / int(len(train_dataset)/train_loader.batch_size) # 1epochでの誤差の平均を計算\n",
    "    print(\"epoch\" + str(epoch+1))\n",
    "    print(\"train_loss:\" + str(train_loss_mean))\n",
    "    train_loss_list.append(train_loss_mean.cpu())# 1epoch毎の平均を格納しておく\n",
    "    \n",
    "    # validation\n",
    "    model.eval() # 評価モード（学習を行わない）であることを明示\n",
    "    \n",
    "    val_loss_add = 0\n",
    "    for i, data in enumerate(val_loader):\n",
    "            \n",
    "        x, t = data\n",
    "        \n",
    "        #GPU環境で動かす際は，下記2行のコメントを外す\n",
    "        x = x.to(\"cuda\")\n",
    "        t = t.to(\"cuda\")\n",
    "        \n",
    "        predict = model(x) # 順伝播計算\n",
    "        \n",
    "        loss = criterion(predict, t) # 誤差の計算\n",
    "        val_loss_add += loss.data\n",
    "        \n",
    "    val_loss_mean = val_loss_add / int(len(val_dataset)/val_loader.batch_size)\n",
    "    print(\"val_loss:\" + str(val_loss_mean))\n",
    "    val_loss_list.append(val_loss_mean.cpu())\n",
    "    \n",
    "    if val_loss_mean < loss_min: # 前に保存したモデルよりもvalidation lossが小さければ，モデルを保存する\n",
    "        torch.save(model.state_dict(), \"/takaya_workspace/self_study/deep_learning/classification_sample/best.model\")\n",
    "        print(\"saved best model!\")\n",
    "        loss_min = val_loss_mean # 今回保存したモデルのvalidation lossをメモしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7591642-d65b-46ab-8099-15f96fb33a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "\n",
    "paths = natsorted(glob(\"/takaya_workspace/self_study/deep_learning/classification_sample/data/test/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "585d4618-2754-44be-b08c-112048620ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = data_transforms(img)\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b80e01fd-5357-4a51-8f3c-4535cac6c6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e56e655-0401-45ed-b7d8-c90c3f145823",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c89500d6-2946-4cbc-9a06-e56d48444036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 3, 224, 224])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a65f19ea-7773-43a0-9c4b-c8163787c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs.to(\"cuda\")\n",
    "\n",
    "model_path = \"/takaya_workspace/self_study/deep_learning/classification_sample/best.model\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path)) # 学習時に保存しておいたモデルのパラメータをコピー\n",
    "\n",
    "y = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fd7232b1-f9c6-4464-b322-687c722101cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(y.argmax(axis=1).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fe3295d6-5b2e-41d9-9b30-16d06b78ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(y.argmax(axis=1).cpu())\n",
    "import pandas as pd\n",
    "pd.Series(results, name=\"class\").to_csv(\"submission.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6a578ca-607e-4aed-bb57-26583f4ac498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for i, idx in enumerate(range(0, 100, 10)):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ccc28-c3a0-4f3c-91b3-4a87279abdb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
