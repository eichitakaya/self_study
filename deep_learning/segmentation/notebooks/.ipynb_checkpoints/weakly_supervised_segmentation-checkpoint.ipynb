{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3625ef1-89dc-4a27-b3b9-f20f61e9acac",
   "metadata": {},
   "source": [
    "# 弱教師あり学習をやってみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a78d60b-ddbf-4100-91d0-98e005cd0fa7",
   "metadata": {},
   "source": [
    "## 弱教師あり学習のおさらい"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549500d-daf3-451e-ad19-9ab1db6de8dd",
   "metadata": {},
   "source": [
    "## 弱教師あり学習による肺セグメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310d6c7-1ff4-4282-b5ce-38628ed00b85",
   "metadata": {},
   "source": [
    "### 問題設定\n",
    "~の論文を参考に，弱教師ありセグメンテーションに挑戦しましょう．\\\n",
    "ここでの「弱教師」は，アノテーションを省エネで付与した場合を考えます．\\\n",
    "具体的には，肺領域をかなり雑に塗ったようなラベルが得られているとします（図１）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25751e03-9d58-4553-9e48-e5619d0f36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "class ChestDataset(Dataset):\n",
    "    def __init__(self, TrainValTest=\"train\", shuffle=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        if TrainValTest == \"train\":\n",
    "            self.img_path_list = sorted(glob.glob(\"/takaya_workspace/self_study/deep_learning/segmentation/data/train/org/*\"))\n",
    "            self.label_path_list = sorted(glob.glob(\"/takaya_workspace/self_study/deep_learning/segmentation/data/train/weak_label/*\"))\n",
    "        elif TrainValTest == \"val\":\n",
    "            self.img_path_list = sorted(glob.glob(\"/takaya_workspace/self_study/deep_learning/segmentation/data/val/org/*\"))\n",
    "            self.label_path_list = sorted(glob.glob(\"/takaya_workspace/self_study/deep_learning/segmentation/data/val/label/*\"))\n",
    "        elif TrainValTest == \"test\":\n",
    "            self.img_path_list = sorted(glob.glob(\"/takaya_workspace/self_study/deep_learning/segmentation/data/test/org/*\"))\n",
    "            self.label_path_list = sorted(glob.glob(\"/takaya_workspace/self_study/deep_learning/segmentation/data/test/label/*\"))\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.img_path_list[index]\n",
    "        label_path = self.label_path_list[index]\n",
    "        img = np.array(Image.open(image_path))\n",
    "        img = self.add_axis(img)\n",
    "        label = np.array(Image.open(label_path))\n",
    "        label = self._label_transform(label)\n",
    "        label = self.add_axis(label)\n",
    "        return img, label\n",
    "    \n",
    "    def _label_transform(self, label):# transformの関数に書き換える\n",
    "        nonzero = np.nonzero(label)\n",
    "        label[nonzero] = 1\n",
    "        return label\n",
    "    \n",
    "    def add_axis(self, arr):# transformの関数に書き換える\n",
    "        arr_new = np.expand_dims(arr, 0)\n",
    "        return arr_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a0bb92a-7c83-48ad-9c62-5afa090e65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chest_train = ChestDataset(TrainValTest=\"train\", shuffle=True)\n",
    "chest_val = ChestDataset(TrainValTest=\"val\", shuffle=False)\n",
    "chest_test = ChestDataset(TrainValTest=\"test\", shuffle=False)\n",
    "train_loader = DataLoader(chest_train, batch_size=5, shuffle=True)\n",
    "val_loader = DataLoader(chest_val, batch_size=5, shuffle=False)\n",
    "test_loader = DataLoader(chest_test, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a8e3a5-a05d-4d8a-8bbf-0f73b081a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class=2, input_channel=1, output_channel=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_class = n_class\n",
    "        \n",
    "        self.input_channel = input_channel\n",
    "        self.output_channel = output_channel\n",
    "        \n",
    "        self.enco1_1 = nn.Conv2d(self.input_channel, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.enco1_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.enco2_1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.enco2_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.enco3_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.enco3_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.enco4_1 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.enco4_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.enco5_1 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)\n",
    "        self.enco5_2 = nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.deco6_1 = nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.deco6_2 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.deco7_1 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.deco7_2 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.deco8_1 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.deco8_2 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.deco9_1 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.deco9_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.final_layer = nn.Conv2d(64, self.output_channel, kernel_size=1)\n",
    "\n",
    "        self.bn1_1 = nn.BatchNorm2d(  64)\n",
    "        self.bn1_2 = nn.BatchNorm2d(  64)\n",
    "\n",
    "        self.bn2_1 = nn.BatchNorm2d(  128)\n",
    "        self.bn2_2 = nn.BatchNorm2d(  128)\n",
    "\n",
    "        self.bn3_1 = nn.BatchNorm2d(  256)\n",
    "        self.bn3_2 = nn.BatchNorm2d(  256)\n",
    "\n",
    "        self.bn4_1 = nn.BatchNorm2d(  512)\n",
    "        self.bn4_2 = nn.BatchNorm2d(  512)\n",
    "\n",
    "        self.bn5_1 = nn.BatchNorm2d(  1024)\n",
    "        self.bn5_2 = nn.BatchNorm2d(  512)\n",
    "\n",
    "        self.bn6_1 = nn.BatchNorm2d(  512)\n",
    "        self.bn6_2 = nn.BatchNorm2d(  256)\n",
    "\n",
    "        self.bn7_1 = nn.BatchNorm2d(  256)\n",
    "        self.bn7_2 = nn.BatchNorm2d(  128)\n",
    "\n",
    "        self.bn8_1 = nn.BatchNorm2d(  128)\n",
    "        self.bn8_2 = nn.BatchNorm2d(  64)\n",
    "\n",
    "        self.bn9_1 = nn.BatchNorm2d(  64)\n",
    "        self.bn9_2 = nn.BatchNorm2d(  64)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)  \n",
    "\n",
    "    def forward(self, x): #x = (batchsize, 3, 360, 480)\n",
    "        #if LRN:\n",
    "        #    x = F.local_response_normalization(x) #Needed for preventing from overfitting\n",
    "\n",
    "        h1_1 = F.relu(self.bn1_1(self.enco1_1(x)))\n",
    "        h1_2 = F.relu(self.bn1_2(self.enco1_2(h1_1)))\n",
    "        pool1, pool1_indice = F.max_pool2d(h1_2, 2, stride=2, return_indices=True) #(batchsize,  64, 180, 240)\n",
    "\n",
    "        h2_1 = F.relu(self.bn2_1(self.enco2_1(pool1)))\n",
    "        h2_2 = F.relu(self.bn2_2(self.enco2_2(h2_1)))\n",
    "        pool2, pool2_indice = F.max_pool2d(h2_2, 2, stride=2, return_indices=True) #(batchsize, 128,  90, 120) \n",
    "\n",
    "        h3_1 = F.relu(self.bn3_1(self.enco3_1(pool2)))\n",
    "        h3_2 = F.relu(self.bn3_2(self.enco3_2(h3_1)))\n",
    "        pool3, pool3_indice = F.max_pool2d(h3_2, 2, stride=2, return_indices=True) #(batchsize, 256,  45,  60) \n",
    "\n",
    "        h4_1 = F.relu(self.bn4_1(self.enco4_1(pool3)))\n",
    "        h4_2 = F.relu(self.bn4_2(self.enco4_2(h4_1)))\n",
    "        pool4, pool4_indice = F.max_pool2d(h4_2, 2, stride=2, return_indices=True) #(batchsize, 256,  23,  30) \n",
    "\n",
    "        h5_1 = F.relu(self.bn5_1(self.enco5_1(pool4)))\n",
    "        h5_2 = F.relu(self.bn5_2(self.enco5_2(h5_1)))\n",
    "        \n",
    "        up5 = F.max_unpool2d(h5_2, pool4_indice, kernel_size=2, stride=2, output_size=(pool3.shape[2], pool3.shape[3]))\n",
    "        h6_1 = F.relu(self.bn6_1(self.deco6_1(torch.cat((up5, h4_2), dim=1))))\n",
    "        h6_2 = F.relu(self.bn6_2(self.deco6_2(h6_1)))\n",
    "\n",
    "        up6 = F.max_unpool2d(h6_2, pool3_indice, kernel_size=2, stride=2, output_size=(pool2.shape[2], pool2.shape[3]))\n",
    "        h7_1 = F.relu(self.bn7_1(self.deco7_1(torch.cat((up6, h3_2), dim=1))))\n",
    "        h7_2 = F.relu(self.bn7_2(self.deco7_2(h7_1)))\n",
    "\n",
    "        up7 = F.max_unpool2d(h7_2, pool2_indice, kernel_size=2, stride=2, output_size=(pool1.shape[2], pool1.shape[3]))\n",
    "        h8_1 = F.relu(self.bn8_1(self.deco8_1(torch.cat((up7, h2_2), dim=1))))\n",
    "        h8_2 = F.relu(self.bn8_2(self.deco8_2(h8_1)))\n",
    "\n",
    "        up8 = F.max_unpool2d(h8_2, pool1_indice, kernel_size=2, stride=2, output_size=(x.shape[2], x.shape[3])) #x = (batchsize, 128, 360, 480)\n",
    "        h9_1 = F.relu(self.bn9_1(self.deco9_1(torch.cat((up8, h1_2), dim=1))))\n",
    "        h9_2 = F.relu(self.bn9_2(self.deco9_2(h9_1)))\n",
    "\n",
    "        h = self.final_layer(h9_2)\n",
    "        #print(h.shape)\n",
    "        #print(t.shape)\n",
    "        predict = h\n",
    "        #loss = \tnn.BCEWithLogitsLoss(h, t)\n",
    "        \n",
    "        #predict = nn.Softmax(h)\n",
    "        return torch.sigmoid(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff4b172d-fc55-4a94-8f05-b0b5f2b50eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "from torch import einsum\n",
    "\n",
    "\n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for individual examples\"\"\"\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        self.save_for_backward(input, target)\n",
    "        eps = 0.0001\n",
    "        self.inter = torch.dot(input.view(-1), target.view(-1))\n",
    "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
    "\n",
    "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
    "        return t\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    def backward(self, grad_output):\n",
    "\n",
    "        input, target = self.saved_variables\n",
    "        grad_input = grad_target = None\n",
    "\n",
    "        if self.needs_input_grad[0]:\n",
    "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
    "                         / (self.union * self.union)\n",
    "        if self.needs_input_grad[1]:\n",
    "            grad_target = None\n",
    "\n",
    "        return grad_input, grad_target\n",
    "\n",
    "\n",
    "def dice_coeff(input, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    if input.is_cuda:\n",
    "        s = torch.FloatTensor(1).cuda().zero_()\n",
    "    else:\n",
    "        s = torch.FloatTensor(1).zero_()\n",
    "\n",
    "    for i, c in enumerate(zip(input, target)):\n",
    "        s = s + DiceCoeff().forward(c[0], c[1])\n",
    "\n",
    "    return s / (i + 1)\n",
    "\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        bce = F.binary_cross_entropy_with_logits(input, target)\n",
    "        smooth = 1e-5\n",
    "        input = torch.sigmoid(input)\n",
    "        num = target.size(0)\n",
    "        input = input.view(num, -1)\n",
    "        target = target.view(num, -1)\n",
    "        intersection = (input * target)\n",
    "        dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n",
    "        dice = 1 - dice.sum() / num\n",
    "        return 0.5 * bce + dice\n",
    "\n",
    "class NaiveSizeLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    This one implement the naive quadratic penalty\n",
    "    penalty = 0                  if a <= pred_size\n",
    "              (a - pred_size)^2  otherwise\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(NaiveSizeLoss, self).__init__()\n",
    "\n",
    "    def __call__(self, pred_softmax, bounds):\n",
    "        #assert simplex(pred_softmax)\n",
    "\n",
    "        B, K, H, W = pred_softmax.shape\n",
    "        #assert bounds.shape == (B, K, 2)\n",
    "\n",
    "        pred_size = einsum(\"bkwh->bk\", pred_softmax)\n",
    "        #print(pred_size)\n",
    "        upper_bounds = bounds[1]\n",
    "        lower_bounds = bounds[0]\n",
    "        assert (upper_bounds >= 0).all() and (lower_bounds >= 0).all()\n",
    "\n",
    "        # size < upper <==> size - upper < 0\n",
    "        # lower < size <==> lower - size < 0\n",
    "        \n",
    "        loss = F.relu(pred_size - upper_bounds) ** 2 + F.relu(lower_bounds - pred_size) ** 2\n",
    "        loss /= (W * H)\n",
    "\n",
    "        return loss.sum() / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2e55a91-1a80-4ecb-9543-6f1181133879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8127/4029499696.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x) / 255\n",
      "/tmp/ipykernel_8127/4029499696.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1\n",
      "train_loss:tensor(0.5749, device='cuda:0')\n",
      "val_loss:tensor(0.6843, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8127/4029499696.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x) / 255\n",
      "/tmp/ipykernel_8127/4029499696.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).float()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model!\n",
      "epoch2\n",
      "train_loss:tensor(0.4801, device='cuda:0')\n",
      "val_loss:tensor(0.6677, device='cuda:0')\n",
      "saved best model!\n",
      "epoch3\n",
      "train_loss:tensor(0.4565, device='cuda:0')\n",
      "val_loss:tensor(0.6441, device='cuda:0')\n",
      "saved best model!\n",
      "epoch4\n",
      "train_loss:tensor(0.4342, device='cuda:0')\n",
      "val_loss:tensor(0.6134, device='cuda:0')\n",
      "saved best model!\n",
      "epoch5\n",
      "train_loss:tensor(0.4048, device='cuda:0')\n",
      "val_loss:tensor(0.5613, device='cuda:0')\n",
      "saved best model!\n",
      "epoch6\n",
      "train_loss:tensor(0.3708, device='cuda:0')\n",
      "val_loss:tensor(0.4691, device='cuda:0')\n",
      "saved best model!\n",
      "epoch7\n",
      "train_loss:tensor(0.3328, device='cuda:0')\n",
      "val_loss:tensor(0.4216, device='cuda:0')\n",
      "saved best model!\n",
      "epoch8\n",
      "train_loss:tensor(0.2992, device='cuda:0')\n",
      "val_loss:tensor(0.4620, device='cuda:0')\n",
      "epoch9\n",
      "train_loss:tensor(0.2736, device='cuda:0')\n",
      "val_loss:tensor(0.4861, device='cuda:0')\n",
      "epoch10\n",
      "train_loss:tensor(0.2528, device='cuda:0')\n",
      "val_loss:tensor(0.4708, device='cuda:0')\n",
      "epoch11\n",
      "train_loss:tensor(0.2409, device='cuda:0')\n",
      "val_loss:tensor(0.4911, device='cuda:0')\n",
      "epoch12\n",
      "train_loss:tensor(0.2317, device='cuda:0')\n",
      "val_loss:tensor(0.5076, device='cuda:0')\n",
      "epoch13\n",
      "train_loss:tensor(0.2208, device='cuda:0')\n",
      "val_loss:tensor(0.4817, device='cuda:0')\n",
      "epoch14\n",
      "train_loss:tensor(0.2140, device='cuda:0')\n",
      "val_loss:tensor(0.4992, device='cuda:0')\n",
      "epoch15\n",
      "train_loss:tensor(0.2090, device='cuda:0')\n",
      "val_loss:tensor(0.5019, device='cuda:0')\n",
      "epoch16\n",
      "train_loss:tensor(0.2052, device='cuda:0')\n",
      "val_loss:tensor(0.4798, device='cuda:0')\n",
      "epoch17\n",
      "train_loss:tensor(0.2023, device='cuda:0')\n",
      "val_loss:tensor(0.4981, device='cuda:0')\n",
      "epoch18\n",
      "train_loss:tensor(0.1986, device='cuda:0')\n",
      "val_loss:tensor(0.5075, device='cuda:0')\n",
      "epoch19\n",
      "train_loss:tensor(0.1940, device='cuda:0')\n",
      "val_loss:tensor(0.5179, device='cuda:0')\n",
      "epoch20\n",
      "train_loss:tensor(0.1903, device='cuda:0')\n",
      "val_loss:tensor(0.5159, device='cuda:0')\n",
      "epoch21\n",
      "train_loss:tensor(0.1856, device='cuda:0')\n",
      "val_loss:tensor(0.5066, device='cuda:0')\n",
      "epoch22\n",
      "train_loss:tensor(0.1830, device='cuda:0')\n",
      "val_loss:tensor(0.5022, device='cuda:0')\n",
      "epoch23\n",
      "train_loss:tensor(0.1831, device='cuda:0')\n",
      "val_loss:tensor(0.5225, device='cuda:0')\n",
      "epoch24\n",
      "train_loss:tensor(0.1840, device='cuda:0')\n",
      "val_loss:tensor(0.4964, device='cuda:0')\n",
      "epoch25\n",
      "train_loss:tensor(0.1809, device='cuda:0')\n",
      "val_loss:tensor(0.4841, device='cuda:0')\n",
      "epoch26\n",
      "train_loss:tensor(0.1812, device='cuda:0')\n",
      "val_loss:tensor(0.5295, device='cuda:0')\n",
      "epoch27\n",
      "train_loss:tensor(0.3082, device='cuda:0')\n",
      "val_loss:tensor(0.6252, device='cuda:0')\n",
      "epoch28\n",
      "train_loss:tensor(1.3417, device='cuda:0')\n",
      "val_loss:tensor(69.3473, device='cuda:0')\n",
      "epoch29\n",
      "train_loss:tensor(0.3012, device='cuda:0')\n",
      "val_loss:tensor(36.7451, device='cuda:0')\n",
      "epoch30\n",
      "train_loss:tensor(0.2659, device='cuda:0')\n",
      "val_loss:tensor(1.1435, device='cuda:0')\n",
      "epoch31\n",
      "train_loss:tensor(0.2334, device='cuda:0')\n",
      "val_loss:tensor(0.4844, device='cuda:0')\n",
      "epoch32\n",
      "train_loss:tensor(0.2208, device='cuda:0')\n",
      "val_loss:tensor(0.4683, device='cuda:0')\n",
      "epoch33\n",
      "train_loss:tensor(0.2094, device='cuda:0')\n",
      "val_loss:tensor(0.4753, device='cuda:0')\n",
      "epoch34\n",
      "train_loss:tensor(0.2020, device='cuda:0')\n",
      "val_loss:tensor(0.5039, device='cuda:0')\n",
      "epoch35\n",
      "train_loss:tensor(0.2239, device='cuda:0')\n",
      "val_loss:tensor(0.4777, device='cuda:0')\n",
      "epoch36\n",
      "train_loss:tensor(0.3077, device='cuda:0')\n",
      "val_loss:tensor(0.7860, device='cuda:0')\n",
      "epoch37\n",
      "train_loss:tensor(0.2989, device='cuda:0')\n",
      "val_loss:tensor(0.6809, device='cuda:0')\n",
      "epoch38\n",
      "train_loss:tensor(0.2634, device='cuda:0')\n",
      "val_loss:tensor(0.5610, device='cuda:0')\n",
      "epoch39\n",
      "train_loss:tensor(0.3465, device='cuda:0')\n",
      "val_loss:tensor(0.6061, device='cuda:0')\n",
      "epoch40\n",
      "train_loss:tensor(0.3647, device='cuda:0')\n",
      "val_loss:tensor(0.4571, device='cuda:0')\n",
      "epoch41\n",
      "train_loss:tensor(0.2676, device='cuda:0')\n",
      "val_loss:tensor(0.4787, device='cuda:0')\n",
      "epoch42\n",
      "train_loss:tensor(0.2481, device='cuda:0')\n",
      "val_loss:tensor(0.4793, device='cuda:0')\n",
      "epoch43\n",
      "train_loss:tensor(0.2316, device='cuda:0')\n",
      "val_loss:tensor(0.4866, device='cuda:0')\n",
      "epoch44\n",
      "train_loss:tensor(0.2192, device='cuda:0')\n",
      "val_loss:tensor(0.4913, device='cuda:0')\n",
      "epoch45\n",
      "train_loss:tensor(0.2117, device='cuda:0')\n",
      "val_loss:tensor(0.4884, device='cuda:0')\n",
      "epoch46\n",
      "train_loss:tensor(0.2977, device='cuda:0')\n",
      "val_loss:tensor(0.4929, device='cuda:0')\n",
      "epoch47\n",
      "train_loss:tensor(0.2684, device='cuda:0')\n",
      "val_loss:tensor(0.4814, device='cuda:0')\n",
      "epoch48\n",
      "train_loss:tensor(0.2324, device='cuda:0')\n",
      "val_loss:tensor(0.4815, device='cuda:0')\n",
      "epoch49\n",
      "train_loss:tensor(0.2184, device='cuda:0')\n",
      "val_loss:tensor(0.4931, device='cuda:0')\n",
      "epoch50\n",
      "train_loss:tensor(0.2093, device='cuda:0')\n",
      "val_loss:tensor(0.5010, device='cuda:0')\n",
      "epoch51\n",
      "train_loss:tensor(0.2060, device='cuda:0')\n",
      "val_loss:tensor(0.4809, device='cuda:0')\n",
      "epoch52\n",
      "train_loss:tensor(0.2380, device='cuda:0')\n",
      "val_loss:tensor(0.5083, device='cuda:0')\n",
      "epoch53\n",
      "train_loss:tensor(0.2620, device='cuda:0')\n",
      "val_loss:tensor(0.5137, device='cuda:0')\n",
      "epoch54\n",
      "train_loss:tensor(0.2601, device='cuda:0')\n",
      "val_loss:tensor(0.5561, device='cuda:0')\n",
      "epoch55\n",
      "train_loss:tensor(0.2441, device='cuda:0')\n",
      "val_loss:tensor(0.5557, device='cuda:0')\n",
      "epoch56\n",
      "train_loss:tensor(0.2236, device='cuda:0')\n",
      "val_loss:tensor(0.5172, device='cuda:0')\n",
      "epoch57\n",
      "train_loss:tensor(0.2098, device='cuda:0')\n",
      "val_loss:tensor(0.4868, device='cuda:0')\n",
      "epoch58\n",
      "train_loss:tensor(0.2011, device='cuda:0')\n",
      "val_loss:tensor(0.4971, device='cuda:0')\n",
      "epoch59\n",
      "train_loss:tensor(0.1951, device='cuda:0')\n",
      "val_loss:tensor(0.4984, device='cuda:0')\n",
      "epoch60\n",
      "train_loss:tensor(0.1917, device='cuda:0')\n",
      "val_loss:tensor(0.4935, device='cuda:0')\n",
      "epoch61\n",
      "train_loss:tensor(0.1910, device='cuda:0')\n",
      "val_loss:tensor(0.4833, device='cuda:0')\n",
      "epoch62\n",
      "train_loss:tensor(0.1942, device='cuda:0')\n",
      "val_loss:tensor(0.4942, device='cuda:0')\n",
      "epoch63\n",
      "train_loss:tensor(0.1907, device='cuda:0')\n",
      "val_loss:tensor(0.5199, device='cuda:0')\n",
      "epoch64\n",
      "train_loss:tensor(0.1927, device='cuda:0')\n",
      "val_loss:tensor(0.5019, device='cuda:0')\n",
      "epoch65\n",
      "train_loss:tensor(0.1952, device='cuda:0')\n",
      "val_loss:tensor(0.4599, device='cuda:0')\n",
      "epoch66\n",
      "train_loss:tensor(0.2018, device='cuda:0')\n",
      "val_loss:tensor(0.4727, device='cuda:0')\n",
      "epoch67\n",
      "train_loss:tensor(0.1962, device='cuda:0')\n",
      "val_loss:tensor(0.5090, device='cuda:0')\n",
      "epoch68\n",
      "train_loss:tensor(0.1931, device='cuda:0')\n",
      "val_loss:tensor(0.5025, device='cuda:0')\n",
      "epoch69\n",
      "train_loss:tensor(0.1882, device='cuda:0')\n",
      "val_loss:tensor(0.5123, device='cuda:0')\n",
      "epoch70\n",
      "train_loss:tensor(0.1875, device='cuda:0')\n",
      "val_loss:tensor(0.4942, device='cuda:0')\n",
      "epoch71\n",
      "train_loss:tensor(0.1891, device='cuda:0')\n",
      "val_loss:tensor(0.4969, device='cuda:0')\n",
      "epoch72\n",
      "train_loss:tensor(0.1872, device='cuda:0')\n",
      "val_loss:tensor(0.4621, device='cuda:0')\n",
      "epoch73\n",
      "train_loss:tensor(0.1889, device='cuda:0')\n",
      "val_loss:tensor(0.5026, device='cuda:0')\n",
      "epoch74\n",
      "train_loss:tensor(0.1872, device='cuda:0')\n",
      "val_loss:tensor(0.5088, device='cuda:0')\n",
      "epoch75\n",
      "train_loss:tensor(0.1909, device='cuda:0')\n",
      "val_loss:tensor(0.4650, device='cuda:0')\n",
      "epoch76\n",
      "train_loss:tensor(0.1910, device='cuda:0')\n",
      "val_loss:tensor(0.5095, device='cuda:0')\n",
      "epoch77\n",
      "train_loss:tensor(0.1865, device='cuda:0')\n",
      "val_loss:tensor(0.5140, device='cuda:0')\n",
      "epoch78\n",
      "train_loss:tensor(0.1814, device='cuda:0')\n",
      "val_loss:tensor(0.5027, device='cuda:0')\n",
      "epoch79\n",
      "train_loss:tensor(0.1775, device='cuda:0')\n",
      "val_loss:tensor(0.5082, device='cuda:0')\n",
      "epoch80\n",
      "train_loss:tensor(0.1788, device='cuda:0')\n",
      "val_loss:tensor(0.5014, device='cuda:0')\n",
      "epoch81\n",
      "train_loss:tensor(0.1815, device='cuda:0')\n",
      "val_loss:tensor(0.4956, device='cuda:0')\n",
      "epoch82\n",
      "train_loss:tensor(0.1866, device='cuda:0')\n",
      "val_loss:tensor(0.4811, device='cuda:0')\n",
      "epoch83\n",
      "train_loss:tensor(0.1878, device='cuda:0')\n",
      "val_loss:tensor(0.5106, device='cuda:0')\n",
      "epoch84\n",
      "train_loss:tensor(0.1790, device='cuda:0')\n",
      "val_loss:tensor(0.5222, device='cuda:0')\n",
      "epoch85\n",
      "train_loss:tensor(0.1810, device='cuda:0')\n",
      "val_loss:tensor(0.5122, device='cuda:0')\n",
      "epoch86\n",
      "train_loss:tensor(0.1813, device='cuda:0')\n",
      "val_loss:tensor(0.5091, device='cuda:0')\n",
      "epoch87\n",
      "train_loss:tensor(0.1780, device='cuda:0')\n",
      "val_loss:tensor(0.5325, device='cuda:0')\n",
      "epoch88\n",
      "train_loss:tensor(0.1765, device='cuda:0')\n",
      "val_loss:tensor(0.5221, device='cuda:0')\n",
      "epoch89\n",
      "train_loss:tensor(0.1804, device='cuda:0')\n",
      "val_loss:tensor(0.4902, device='cuda:0')\n",
      "epoch90\n",
      "train_loss:tensor(0.1859, device='cuda:0')\n",
      "val_loss:tensor(0.4996, device='cuda:0')\n",
      "epoch91\n",
      "train_loss:tensor(0.1781, device='cuda:0')\n",
      "val_loss:tensor(0.5027, device='cuda:0')\n",
      "epoch92\n",
      "train_loss:tensor(0.1783, device='cuda:0')\n",
      "val_loss:tensor(0.5042, device='cuda:0')\n",
      "epoch93\n",
      "train_loss:tensor(0.1760, device='cuda:0')\n",
      "val_loss:tensor(0.5105, device='cuda:0')\n",
      "epoch94\n",
      "train_loss:tensor(0.1736, device='cuda:0')\n",
      "val_loss:tensor(0.5100, device='cuda:0')\n",
      "epoch95\n",
      "train_loss:tensor(0.1744, device='cuda:0')\n",
      "val_loss:tensor(0.5066, device='cuda:0')\n",
      "epoch96\n",
      "train_loss:tensor(0.1728, device='cuda:0')\n",
      "val_loss:tensor(0.5216, device='cuda:0')\n",
      "epoch97\n",
      "train_loss:tensor(0.1801, device='cuda:0')\n",
      "val_loss:tensor(0.4723, device='cuda:0')\n",
      "epoch98\n",
      "train_loss:tensor(0.1867, device='cuda:0')\n",
      "val_loss:tensor(0.5049, device='cuda:0')\n",
      "epoch99\n",
      "train_loss:tensor(0.2104, device='cuda:0')\n",
      "val_loss:tensor(0.5489, device='cuda:0')\n",
      "epoch100\n",
      "train_loss:tensor(0.2320, device='cuda:0')\n",
      "val_loss:tensor(0.5143, device='cuda:0')\n",
      "epoch101\n",
      "train_loss:tensor(0.2399, device='cuda:0')\n",
      "val_loss:tensor(0.4957, device='cuda:0')\n",
      "epoch102\n",
      "train_loss:tensor(0.2219, device='cuda:0')\n",
      "val_loss:tensor(0.5125, device='cuda:0')\n",
      "epoch103\n",
      "train_loss:tensor(0.2117, device='cuda:0')\n",
      "val_loss:tensor(0.4994, device='cuda:0')\n",
      "epoch104\n",
      "train_loss:tensor(0.2032, device='cuda:0')\n",
      "val_loss:tensor(0.4661, device='cuda:0')\n",
      "epoch105\n",
      "train_loss:tensor(0.2058, device='cuda:0')\n",
      "val_loss:tensor(0.4956, device='cuda:0')\n",
      "epoch106\n",
      "train_loss:tensor(0.1877, device='cuda:0')\n",
      "val_loss:tensor(0.4887, device='cuda:0')\n",
      "epoch107\n",
      "train_loss:tensor(0.1856, device='cuda:0')\n",
      "val_loss:tensor(0.4895, device='cuda:0')\n",
      "epoch108\n",
      "train_loss:tensor(0.1828, device='cuda:0')\n",
      "val_loss:tensor(0.4881, device='cuda:0')\n",
      "epoch109\n",
      "train_loss:tensor(0.1817, device='cuda:0')\n",
      "val_loss:tensor(0.5049, device='cuda:0')\n",
      "epoch110\n",
      "train_loss:tensor(0.1804, device='cuda:0')\n",
      "val_loss:tensor(0.5140, device='cuda:0')\n",
      "epoch111\n",
      "train_loss:tensor(0.1809, device='cuda:0')\n",
      "val_loss:tensor(0.5024, device='cuda:0')\n",
      "epoch112\n",
      "train_loss:tensor(0.1849, device='cuda:0')\n",
      "val_loss:tensor(0.5331, device='cuda:0')\n",
      "epoch113\n",
      "train_loss:tensor(0.1822, device='cuda:0')\n",
      "val_loss:tensor(0.5213, device='cuda:0')\n",
      "epoch114\n",
      "train_loss:tensor(0.1815, device='cuda:0')\n",
      "val_loss:tensor(0.4969, device='cuda:0')\n",
      "epoch115\n",
      "train_loss:tensor(0.1807, device='cuda:0')\n",
      "val_loss:tensor(0.5058, device='cuda:0')\n",
      "epoch116\n",
      "train_loss:tensor(0.1805, device='cuda:0')\n",
      "val_loss:tensor(0.5175, device='cuda:0')\n",
      "epoch117\n",
      "train_loss:tensor(0.1774, device='cuda:0')\n",
      "val_loss:tensor(0.5101, device='cuda:0')\n",
      "epoch118\n",
      "train_loss:tensor(0.1759, device='cuda:0')\n",
      "val_loss:tensor(0.5140, device='cuda:0')\n",
      "epoch119\n",
      "train_loss:tensor(0.1786, device='cuda:0')\n",
      "val_loss:tensor(0.4949, device='cuda:0')\n",
      "epoch120\n",
      "train_loss:tensor(0.1800, device='cuda:0')\n",
      "val_loss:tensor(0.5108, device='cuda:0')\n",
      "epoch121\n",
      "train_loss:tensor(0.1748, device='cuda:0')\n",
      "val_loss:tensor(0.5324, device='cuda:0')\n",
      "epoch122\n",
      "train_loss:tensor(0.1746, device='cuda:0')\n",
      "val_loss:tensor(0.5077, device='cuda:0')\n",
      "epoch123\n",
      "train_loss:tensor(0.1717, device='cuda:0')\n",
      "val_loss:tensor(0.5111, device='cuda:0')\n",
      "epoch124\n",
      "train_loss:tensor(0.1721, device='cuda:0')\n",
      "val_loss:tensor(0.5209, device='cuda:0')\n",
      "epoch125\n",
      "train_loss:tensor(0.1723, device='cuda:0')\n",
      "val_loss:tensor(0.5058, device='cuda:0')\n",
      "epoch126\n",
      "train_loss:tensor(0.1702, device='cuda:0')\n",
      "val_loss:tensor(0.5228, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m train_loss_add \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# 1エポック分の誤差を累積しておくための変数\u001b[39;00m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m#学習モードであることを明示\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     36\u001b[0m     x, t \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     37\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    560\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:84\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m     transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:84\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m     transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem_type))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.2/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:57\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(batch, \u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43melem_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# モデルの定義\n",
    "model = UNet()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# optimizerの準備\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# 誤差関数の定義\n",
    "#criterion = BCEDiceLoss()\n",
    "bce = nn.BCELoss()\n",
    "sl = NaiveSizeLoss()\n",
    "\n",
    "# 訓練ループ\n",
    "\n",
    "batchsize = 5\n",
    "\n",
    "train_size = len(chest_train)\n",
    "val_size = len(chest_val)\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "train_loss_list = [] # epoch毎のtrain_lossを保存しておくための入れ物\n",
    "val_loss_list = [] # epoch毎のvalidation_lossを保存しておくための入れ物\n",
    "\n",
    "loss_min = 100000\n",
    "\n",
    "bounds = torch.Tensor([13175.0, 29502.0])\n",
    "#bounds = torch.Tensor([25000.0, 29502.0])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss_add = 0 # 1エポック分の誤差を累積しておくための変数\n",
    "    model.train() #学習モードであることを明示\n",
    "    for i, data in enumerate(train_loader):\n",
    "        x, t = data\n",
    "        x = torch.tensor(x) / 255\n",
    "        t = torch.tensor(t).float()\n",
    "        \n",
    "        x = x.to(\"cuda\")\n",
    "        t = t.to(\"cuda\")\n",
    "        \n",
    "        predict = model(x)\n",
    "        \n",
    "        bce_loss = bce(predict, t)\n",
    "        sl_loss = sl(predict, bounds)\n",
    "        loss = bce_loss + sl_loss\n",
    "        #loss = bce_loss\n",
    "        model.zero_grad()\n",
    "        loss.backward() # 誤差逆伝播法により，各パラメータについての勾配を求める\n",
    "        optimizer.step() # 上で求めた勾配を用いて，山が低くなっている方へ一歩進む\n",
    "        \n",
    "        train_loss_add += loss.data\n",
    "        \n",
    "    train_loss_mean = train_loss_add / int(train_size/batchsize)\n",
    "    print(\"epoch\" + str(epoch+1))\n",
    "    #print(bce_loss, sl_loss)\n",
    "    print(\"train_loss:\" + str(train_loss_mean))\n",
    "    train_loss_list.append(train_loss_mean.cpu())\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss_add = 0\n",
    "    num = 0\n",
    "    for i, data in enumerate(val_loader):\n",
    "            \n",
    "        #cudaに変換\n",
    "        x, t = data\n",
    "        x = torch.tensor(x) / 255\n",
    "        t = torch.tensor(t).float()\n",
    "        x = x.to(\"cuda\")\n",
    "        t = t.to(\"cuda\")\n",
    "        predict = model(x)\n",
    "        \n",
    "        loss = bce(predict, t)\n",
    "        val_loss_add += loss.data\n",
    "        \n",
    "    val_loss_mean = val_loss_add / int(val_size/batchsize)\n",
    "    print(\"val_loss:\" + str(val_loss_mean))\n",
    "    val_loss_list.append(val_loss_mean.cpu())\n",
    "    \n",
    "    if val_loss_mean < loss_min:\n",
    "        torch.save(model.state_dict(), \"/takaya_workspace/self_study/deep_learning/segmentation/models/best.model\")\n",
    "        print(\"saved best model!\")\n",
    "        loss_min = val_loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6d469ec-d03e-41e9-b3c4-0858ac083ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f106048f790>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss_list)\n",
    "plt.plot(val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4dc2078-f2bb-432a-9cf5-6034ad2e3ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8127/3183670863.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x) / 255\n",
      "/tmp/ipykernel_8127/3183670863.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).float()\n",
      "/tmp/ipykernel_8127/3183670863.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x) / 255\n",
      "/tmp/ipykernel_8127/3183670863.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t).float()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DICE係数とIOUについて説明，実装\n",
    "# 質的評価のための可視化方法\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def thresholding(inference,  threshold=0.5):\n",
    "    # 入力は2チャンネルのVariable\n",
    "    inference = inference.data.cpu() # 最後の一枚の１チャンネル目\n",
    "\n",
    "    mask1 = inference >= threshold\n",
    "    inference[mask1] = 255\n",
    "\n",
    "    mask0 = inference < threshold\n",
    "    inference[mask0] = 0\n",
    "    \n",
    "    return inference\n",
    "\n",
    "def calc_all(tp, pp):\n",
    "    mask = pp != 0\n",
    "    pp[mask] = 1\n",
    "    tn, fp, fn, tp = confusion_matrix(tp.flatten(), pp.flatten()).ravel()\n",
    "    presicion = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    dice = tp / (tp + ((1/2)*(fp+fn)))\n",
    "    iou = tp / (tp + fp + fn)\n",
    "    return presicion, recall, dice, iou\n",
    "\n",
    "test_size = len(chest_test)\n",
    "\n",
    "iou_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "dice_list = []\n",
    "test_loss_add = 0\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "num = 0\n",
    "\n",
    "model = UNet(input_channel=1, output_channel=1)\n",
    "model = model.to(\"cuda\")\n",
    "model_path = '/takaya_workspace/self_study/deep_learning/segmentation/models/best.model'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "dice_list = []\n",
    "iou_list = []\n",
    "\n",
    "for i,data in enumerate(test_loader):\n",
    "    x, t = data\n",
    "    x = torch.tensor(x) / 255\n",
    "    t = torch.tensor(t).float()\n",
    "    \n",
    "    x = x.to(\"cuda\")\n",
    "    t = t.to(\"cuda\")\n",
    "        \n",
    "    predict = model(x)\n",
    "    predict_imgs = thresholding(predict, threshold=0.5)\n",
    "    \n",
    "    for j in range(batch_size):\n",
    "        img = np.array(predict_imgs[j][0])\n",
    "        xx = np.array(x[j][0].cpu())\n",
    "        tt = np.array(t[j][0].cpu())\n",
    "        \n",
    "        precision, recall, dice, iou = calc_all(img/255, tt)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        dice_list.append(dice)\n",
    "        iou_list.append(iou)\n",
    "    \n",
    "        plt.subplot(1, 3, 1)#1桁目 -- グラフの行数、2桁目 -- グラフの列数、3桁目 -- グラフの番号、subplot(2,3,1)の記載でも良い。\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"input\")\n",
    "        plt.imshow(xx, cmap = \"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"target\")\n",
    "        plt.imshow(tt, cmap = \"gray\")\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"output\\n(iou=\" + str(iou) + \")\")\n",
    "        plt.imshow(img, cmap = \"gray\")\n",
    "        plt.savefig(\"/takaya_workspace/self_study/deep_learning/segmentation/results/\" + str(i) + \"_\" + str(j) + \".png\")\n",
    "\n",
    "precision_list = np.array(precision_list)\n",
    "recall_list = np.array(recall_list)\n",
    "recall_list = np.nan_to_num(recall_list)\n",
    "dice_list = np.array(dice_list)\n",
    "iou_list = np.array(iou_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06f8c03f-e6ef-4706-a858-4cd9f2d9d93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20862.0\n",
      "17155.0\n",
      "14825.0\n",
      "13175.0\n",
      "18577.0\n",
      "24999.0\n",
      "22108.0\n",
      "16084.0\n",
      "18535.0\n",
      "17977.0\n",
      "23153.0\n",
      "24524.0\n",
      "22361.0\n",
      "15265.0\n",
      "19724.0\n",
      "23169.0\n",
      "25627.0\n",
      "19298.0\n",
      "19090.0\n",
      "16348.0\n",
      "20433.0\n",
      "29502.0\n",
      "19148.0\n",
      "19397.0\n",
      "20325.0\n",
      "21373.0\n",
      "21558.0\n",
      "16999.0\n",
      "18802.0\n",
      "20906.0\n",
      "16925.0\n",
      "19799.0\n",
      "13711.0\n",
      "18784.0\n",
      "20239.0\n",
      "19283.0\n",
      "18421.0\n",
      "19968.0\n",
      "16340.0\n",
      "18576.0\n"
     ]
    }
   ],
   "source": [
    "label_list = glob.glob(\"/takaya_workspace/self_study/deep_learning/segmentation/data/train/label/*\")\n",
    "for i in range(len(label_list)):\n",
    "    label = Image.open(label_list[i])\n",
    "    label = np.array(label) / 255\n",
    "    print(label.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "598348ff-e826-4ce5-a29a-4f7c5133984b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d18f9ee-7b22-4c02-927b-667e1e9f1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape((5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093704eb-3cf9-42c0-9179-e9978a919642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3caa573-b7c5-4657-9991-1fc4093b92bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
