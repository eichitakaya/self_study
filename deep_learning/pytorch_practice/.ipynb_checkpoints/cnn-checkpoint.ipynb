{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading data\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"/deep_takaya/self_study/deep_learning/data\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"/deep_takaya/self_study/deep_learning/data\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "# Difinition of Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of the network\n",
    "class AlexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.classifier = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x), inplace=True), kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x), inplace=True), kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv3(x), inplace=True)\n",
    "        x = F.relu(self.conv4(x), inplace=True)\n",
    "        x = F.max_pool2d(F.relu(self.conv5(x), inplace=True), kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "net = AlexNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimization function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0351, valloss: 0.0325, val_acc: 0.2254\n",
      "Epoch [2/20], Loss: 0.0289, valloss: 0.0271, val_acc: 0.3632\n",
      "Epoch [3/20], Loss: 0.0240, valloss: 0.0228, val_acc: 0.4724\n",
      "Epoch [4/20], Loss: 0.0216, valloss: 0.0205, val_acc: 0.5261\n",
      "Epoch [5/20], Loss: 0.0198, valloss: 0.0200, val_acc: 0.5408\n",
      "Epoch [6/20], Loss: 0.0183, valloss: 0.0198, val_acc: 0.5461\n",
      "Epoch [7/20], Loss: 0.0170, valloss: 0.0177, val_acc: 0.6008\n",
      "Epoch [8/20], Loss: 0.0157, valloss: 0.0171, val_acc: 0.6108\n",
      "Epoch [9/20], Loss: 0.0146, valloss: 0.0177, val_acc: 0.6095\n",
      "Epoch [10/20], Loss: 0.0134, valloss: 0.0185, val_acc: 0.5938\n",
      "Epoch [11/20], Loss: 0.0123, valloss: 0.0169, val_acc: 0.6327\n",
      "Epoch [12/20], Loss: 0.0113, valloss: 0.0182, val_acc: 0.6189\n",
      "Epoch [13/20], Loss: 0.0103, valloss: 0.0170, val_acc: 0.6447\n",
      "Epoch [14/20], Loss: 0.0095, valloss: 0.0182, val_acc: 0.6288\n",
      "Epoch [15/20], Loss: 0.0085, valloss: 0.0182, val_acc: 0.6318\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "num_epochs = 20\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    #train===========================\n",
    "    net.train()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Don't be adapted view()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_train_acc = train_acc / len(train_loader.dataset)\n",
    "    \n",
    "    #val===============================\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Don't be adapted view()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "        avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "        avg_val_acc = val_acc / len(test_loader.dataset)\n",
    "        \n",
    "        print(\"Epoch [{}/{}], Loss: {loss:.4f}, valloss: {val_loss:.4f}, val_acc: {val_acc:.4f}\".format(epoch+1, num_epochs, i+1, loss=avg_train_loss, val_loss=avg_val_loss, val_acc=avg_val_acc))\n",
    "        \n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        train_acc_list.append(avg_train_acc)\n",
    "        val_loss_list.append(avg_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), train_loss_list, color=\"blue\", linestyle=\"-\", label=\"train_loss\")\n",
    "plt.plot(range(num_epochs), val_loss_list, color=\"green\", linestyle=\"--\", label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Trainig and validation loss\")\n",
    "plt.grid()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(num_epochs), train_acc_list, color=\"blue\", linestyle=\"-\", label=\"train_acc\")\n",
    "plt.plot(range(num_epochs), val_acc_list, color=\"green\", linestyle=\"--\", label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load trained network\n",
    "torch.save(net.state_dict(), \"alexnet.ckpt\")\n",
    "\n",
    "net2 = MLPNet().to(device)\n",
    "net2.load_state_dict(torch.load(\"alexnet.ckpt\"))\n",
    "\n",
    "# Inference\n",
    "net2.eval()\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    test_acc = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.view(-1, 32*32*3).to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net2(images)\n",
    "        test_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    print(\"accracy; {} %\".format(100 * test_acc / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3-4.1.1]",
   "language": "python",
   "name": "Python [anaconda3-4.1.1]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
