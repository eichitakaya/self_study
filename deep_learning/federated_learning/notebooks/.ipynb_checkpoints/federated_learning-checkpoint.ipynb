{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f6d0a5-dd87-49cb-9a16-6501cd3021cb",
   "metadata": {},
   "source": [
    "## MNISTで連合学習を試してみよう\n",
    "\n",
    "今回は，深層学習の実践でとてもとてもよく使われている手書き数字データセット，MNISTを使って，連合学習を実践していきましょう．\n",
    "\n",
    "MNISTには60000枚の訓練用画像と10000枚のテスト用画像が含まれていますが，今回はあえて一部の画像しか得られないケースを想定します．\n",
    "\n",
    "まずは，Pytorchのtorchvisionに含まれているdatasetsから，MNISTを読み込みます．\\\n",
    "事前に配布した資料には，MNISTのデータセットが含まれていますが，もし手元にない場合はdownload=Trueとすることで，任意のフォルダに自動でダウンロードされます．\n",
    "\n",
    "必要なライブラリもまとめてインポートしておきましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e79e97-291c-494f-8783-71d7e0a2ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3b2428-2824-4b0e-9bdd-b48165cc1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_test = datasets.MNIST(\"./data\", train=False, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae7b0c94-943d-4f35-9ebc-3bf4c3e67fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb8294-8e04-435e-90e1-3c63e339c9ff",
   "metadata": {},
   "source": [
    "前回実践した肺野セグメンテーションでは，ChestDatasetというデータセットクラスを自作し，DataLoaderで包み込みました（下記セルを参照）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baabb45a-6081-4dbc-bd12-0dea47c48a9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# こちらのセルは参照用ですので，実行してもエラーが出ます．\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChestDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, TrainValTest\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# こちらのセルは参照用ですので，実行してもエラーが出ます．\n",
    "class ChestDataset(Dataset):\n",
    "    def __init__(self, TrainValTest=\"train\"):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        どのデータを使うのかを記述する部分\n",
    "        \"\"\"\n",
    "        if TrainValTest == \"train\":\n",
    "            self.img_path_list = sorted(glob.glob(\"/content/drive/MyDrive/segmentation/data/train/org/*\"))\n",
    "            self.label_path_list = sorted(glob.glob(\"/content/drive/MyDrive/segmentation/data/train/label/*\"))\n",
    "        elif TrainValTest == \"val\":\n",
    "            self.img_path_list = sorted(glob.glob(\"/content/drive/MyDrive/segmentation/data/val/org/*\"))\n",
    "            self.label_path_list = sorted(glob.glob(\"/content/drive/MyDrive/segmentation/data/val/label/*\"))\n",
    "        elif TrainValTest == \"test\":\n",
    "            self.img_path_list = sorted(glob.glob(\"/content/drive/MyDrive/segmentation/data/test/org/*\"))\n",
    "            self.label_path_list = sorted(glob.glob(\"/content/drive/MyDrive/segmentation/data/test/label/*\"))    \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        データがいくつあるのかを数える\n",
    "        \"\"\"\n",
    "        return len(self.img_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        データをどのような形で取り出すのか記述する\n",
    "        \"\"\"\n",
    "        image_path = self.img_path_list[index] # ファイル名\n",
    "        label_path = self.label_path_list[index] # ファイル名\n",
    "        \n",
    "        img = Image.open(image_path) # ファイル名を与えて画像を取り出す\n",
    "        img = np.array(img) # 画像をnumpy形式の行列へ変換\n",
    "        img = np.expand_dims(img, 0) # 1チャンネルであることを明示する（256, 256）→ (1, 256, 256)\n",
    "        img = torch.tensor(img) # 行列をpytorchで扱える形式（tensor型）に変換する\n",
    "        img = img / 255 # 0~255までの値を0~1までの値に変換する\n",
    "        \n",
    "        label = Image.open(label_path) # ファイル名を与えてラベルを取り出す\n",
    "        label = np.array(label) # ラベルをnumpy形式の行列へ変換\n",
    "        label = np.expand_dims(label, 0)\n",
    "        label = torch.tensor(label)\n",
    "        label = label = label / 255 # 肺野領域は255，それ以外は0となっているので，255で割って0 or 1に変換する\n",
    "        label = label.float() # 行列の値をfloat型に変換する（pytorchの都合）\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9fc54-bba8-46ef-a448-56b1de933bef",
   "metadata": {},
   "source": [
    "MNISTの場合は，この時点ですでにdatasetの型になっているので，あとはDataLoaderで包み込めば，前回と同様に学習ループでミニバッチサイズ分ずつ取り出すことができます．\\\n",
    "ただし，今回は連合学習を行いたいので，これに細工をして少ないデータ数のsmall MNISTを複数（施設が複数あることを想定）作ることにしましょう．\n",
    "\n",
    "ひとまず施設数は3つとし，各施設では600個ずつのサンプルが得られたという設定で，データセットを作っていきます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "91a8640c-f810-4c0f-9f36-56308123c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_facilitates = 10\n",
    "n_samples = 100\n",
    "train_size = int(n_samples * 0.8) \n",
    "val_size = n_samples - train_size \n",
    "\n",
    "dataset_dir = {}\n",
    "\n",
    "for i in range(n_facilitates):\n",
    "    small_dataset, mnist_train = torch.utils.data.random_split(mnist_train, [n_samples, len(mnist_train)-n_samples])\n",
    "    dataset_dir[\"Hospital_\" + str(i+1)] = small_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2034bc-36b3-4a9a-8ecf-2d04e784fdd0",
   "metadata": {},
   "source": [
    "上記のコードでは，60000サンプルのMNISTから100サンプルを切り出しては，dataset_dirに病院名と紐付けながら格納しています．このようにしておくと，あとでHospital_1のデータを使いたい時に下記のように呼び出せばすぐに対応するデータセットを取り出すことができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d9d27ef9-c3eb-4cf3-9dd7-576bdfd710e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hospital_1': <torch.utils.data.dataset.Subset at 0x7f5965cf9070>,\n",
       " 'Hospital_2': <torch.utils.data.dataset.Subset at 0x7f5996bad520>,\n",
       " 'Hospital_3': <torch.utils.data.dataset.Subset at 0x7f5964d45b20>,\n",
       " 'Hospital_4': <torch.utils.data.dataset.Subset at 0x7f594df101f0>,\n",
       " 'Hospital_5': <torch.utils.data.dataset.Subset at 0x7f594dedf460>,\n",
       " 'Hospital_6': <torch.utils.data.dataset.Subset at 0x7f594df3eac0>,\n",
       " 'Hospital_7': <torch.utils.data.dataset.Subset at 0x7f594df3ea00>,\n",
       " 'Hospital_8': <torch.utils.data.dataset.Subset at 0x7f594dec54f0>,\n",
       " 'Hospital_9': <torch.utils.data.dataset.Subset at 0x7f594dec5940>,\n",
       " 'Hospital_10': <torch.utils.data.dataset.Subset at 0x7f594dec5d00>}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0859731-9bef-46fd-a4c6-458f5f68ef9f",
   "metadata": {},
   "source": [
    "連合学習を行う前に，単一施設ではどの程度の分類精度が叩き出せるのか，確認しておきましょう．\\\n",
    "まずは例によって，データセットをtrainとvalに分割し，それぞれをDataLoaderで包み込みます．\\\n",
    "test用のデータについては，先程読み込んだものをそのままDataLoaderで包み込みます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0919938-5bd2-4555-9f5a-13f574251954",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_small = dataset_dir[\"Hospital_1\"]\n",
    "\n",
    "n_samples = len(mnist_small) \n",
    "train_size = int(n_samples * 0.8) \n",
    "val_size = n_samples - train_size \n",
    "\n",
    "mnist_small_train, mnist_small_val = torch.utils.data.random_split(mnist_small, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(mnist_small_train, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(mnist_small_val, batch_size=10, shuffle=False)\n",
    "test_loader = DataLoader(mnist_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e774d-8382-4819-a595-2de6dbe0d0de",
   "metadata": {},
   "source": [
    "これでデータセットの準備は完了しました！\\\n",
    "ここからは，例によってネットワークや誤差関数を定義し，少数サンプルでの深層学習を行ってみましょう．\n",
    "\n",
    "今回は，できる限り単純で時間のかからない実験を行うために，3層の全結合ニューラルネットワークを用意します．\\\n",
    "解きたい問題は多クラス分類問題なので，誤差関数には交差エントロピーを用います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a8f11f29-8113-47ad-a1e6-45c283bd56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "59cc1ec8-a51e-46bb-8835-0abed4e30b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 誤差関数の定義\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b80dd1f3-c690-42c2-aad8-0e887ae7d1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_764/3254277216.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1\n",
      "train_loss:tensor(2.2659, device='cuda:0')\n",
      "val_loss:tensor(2.2457, device='cuda:0')\n",
      "saved best model!\n",
      "epoch2\n",
      "train_loss:tensor(2.0725, device='cuda:0')\n",
      "val_loss:tensor(2.1153, device='cuda:0')\n",
      "saved best model!\n",
      "epoch3\n",
      "train_loss:tensor(1.8776, device='cuda:0')\n",
      "val_loss:tensor(2.0187, device='cuda:0')\n",
      "saved best model!\n",
      "epoch4\n",
      "train_loss:tensor(1.7455, device='cuda:0')\n",
      "val_loss:tensor(1.8955, device='cuda:0')\n",
      "saved best model!\n",
      "epoch5\n",
      "train_loss:tensor(1.6399, device='cuda:0')\n",
      "val_loss:tensor(1.8762, device='cuda:0')\n",
      "saved best model!\n",
      "epoch6\n",
      "train_loss:tensor(1.5806, device='cuda:0')\n",
      "val_loss:tensor(1.8538, device='cuda:0')\n",
      "saved best model!\n",
      "epoch7\n",
      "train_loss:tensor(1.5526, device='cuda:0')\n",
      "val_loss:tensor(1.8145, device='cuda:0')\n",
      "saved best model!\n",
      "epoch8\n",
      "train_loss:tensor(1.5350, device='cuda:0')\n",
      "val_loss:tensor(1.8077, device='cuda:0')\n",
      "saved best model!\n",
      "epoch9\n",
      "train_loss:tensor(1.5289, device='cuda:0')\n",
      "val_loss:tensor(1.8141, device='cuda:0')\n",
      "epoch10\n",
      "train_loss:tensor(1.5250, device='cuda:0')\n",
      "val_loss:tensor(1.8031, device='cuda:0')\n",
      "saved best model!\n",
      "epoch11\n",
      "train_loss:tensor(1.5214, device='cuda:0')\n",
      "val_loss:tensor(1.8002, device='cuda:0')\n",
      "saved best model!\n",
      "epoch12\n",
      "train_loss:tensor(1.5134, device='cuda:0')\n",
      "val_loss:tensor(1.7954, device='cuda:0')\n",
      "saved best model!\n",
      "epoch13\n",
      "train_loss:tensor(1.5121, device='cuda:0')\n",
      "val_loss:tensor(1.8030, device='cuda:0')\n",
      "epoch14\n",
      "train_loss:tensor(1.5116, device='cuda:0')\n",
      "val_loss:tensor(1.8010, device='cuda:0')\n",
      "epoch15\n",
      "train_loss:tensor(1.5109, device='cuda:0')\n",
      "val_loss:tensor(1.7942, device='cuda:0')\n",
      "saved best model!\n",
      "epoch16\n",
      "train_loss:tensor(1.5106, device='cuda:0')\n",
      "val_loss:tensor(1.7901, device='cuda:0')\n",
      "saved best model!\n",
      "epoch17\n",
      "train_loss:tensor(1.5104, device='cuda:0')\n",
      "val_loss:tensor(1.7885, device='cuda:0')\n",
      "saved best model!\n",
      "epoch18\n",
      "train_loss:tensor(1.5102, device='cuda:0')\n",
      "val_loss:tensor(1.7870, device='cuda:0')\n",
      "saved best model!\n",
      "epoch19\n",
      "train_loss:tensor(1.5101, device='cuda:0')\n",
      "val_loss:tensor(1.7855, device='cuda:0')\n",
      "saved best model!\n",
      "epoch20\n",
      "train_loss:tensor(1.5099, device='cuda:0')\n",
      "val_loss:tensor(1.7848, device='cuda:0')\n",
      "saved best model!\n",
      "epoch21\n",
      "train_loss:tensor(1.5098, device='cuda:0')\n",
      "val_loss:tensor(1.7834, device='cuda:0')\n",
      "saved best model!\n",
      "epoch22\n",
      "train_loss:tensor(1.5097, device='cuda:0')\n",
      "val_loss:tensor(1.7812, device='cuda:0')\n",
      "saved best model!\n",
      "epoch23\n",
      "train_loss:tensor(1.5097, device='cuda:0')\n",
      "val_loss:tensor(1.7808, device='cuda:0')\n",
      "saved best model!\n",
      "epoch24\n",
      "train_loss:tensor(1.5096, device='cuda:0')\n",
      "val_loss:tensor(1.7803, device='cuda:0')\n",
      "saved best model!\n",
      "epoch25\n",
      "train_loss:tensor(1.5095, device='cuda:0')\n",
      "val_loss:tensor(1.7802, device='cuda:0')\n",
      "saved best model!\n",
      "epoch26\n",
      "train_loss:tensor(1.5095, device='cuda:0')\n",
      "val_loss:tensor(1.7787, device='cuda:0')\n",
      "saved best model!\n",
      "epoch27\n",
      "train_loss:tensor(1.5094, device='cuda:0')\n",
      "val_loss:tensor(1.7784, device='cuda:0')\n",
      "saved best model!\n",
      "epoch28\n",
      "train_loss:tensor(1.5094, device='cuda:0')\n",
      "val_loss:tensor(1.7775, device='cuda:0')\n",
      "saved best model!\n",
      "epoch29\n",
      "train_loss:tensor(1.5093, device='cuda:0')\n",
      "val_loss:tensor(1.7762, device='cuda:0')\n",
      "saved best model!\n",
      "epoch30\n",
      "train_loss:tensor(1.5093, device='cuda:0')\n",
      "val_loss:tensor(1.7759, device='cuda:0')\n",
      "saved best model!\n"
     ]
    }
   ],
   "source": [
    "# モデルの定義\n",
    "model = MLP()\n",
    "\n",
    "# GPUを使う場合は，下記のコメントを外す\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# optimizer（勾配降下法のアルゴリズム）の準備\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 学習ループ\n",
    "epochs = 30 #ミニバッチのサンプリングが一巡 = 1 epoch\n",
    "\n",
    "train_loss_list = [] # epoch毎のtrain_lossを保存しておくための入れ物\n",
    "val_loss_list = [] # epoch毎のvalidation_lossを保存しておくための入れ物\n",
    "\n",
    "loss_min = 100000 # validation_lossが小さくなった場合にのみモデルを保存しておくためのメモ\n",
    "\n",
    "# ここからループ開始\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss_add = 0 # 1エポック分の誤差を累積しておくための変数\n",
    "    \n",
    "    model.train() #学習モードであることを明示\n",
    "   \n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        x, t = data # ①データの読み込み\n",
    "        \n",
    "        #GPU環境で動かす際は，下記2行のコメントを外す\n",
    "        x = x.to(\"cuda\")\n",
    "        t = t.to(\"cuda\")\n",
    "        \n",
    "        predict = model(x) # ②順伝播計算\n",
    "        \n",
    "        loss = criterion(predict, t) # ③誤差の計算\n",
    "        \n",
    "        model.zero_grad()# 誤差逆伝播法のための準備\n",
    "        loss.backward() # ④誤差逆伝播法による誤差の計算\n",
    "        \n",
    "        optimizer.step() # ⑤勾配を用いてパラメータを更新\n",
    "        \n",
    "        train_loss_add += loss.data # あとで平均を計算するために，誤差を累積しておく\n",
    "        \n",
    "    train_loss_mean = train_loss_add / int(len(mnist_small_train)/train_loader.batch_size) # 1epochでの誤差の平均を計算\n",
    "    print(\"epoch\" + str(epoch+1))\n",
    "    print(\"train_loss:\" + str(train_loss_mean))\n",
    "    train_loss_list.append(train_loss_mean.cpu())# 1epoch毎の平均を格納しておく\n",
    "    \n",
    "    # validation\n",
    "    model.eval() # 評価モード（学習を行わない）であることを明示\n",
    "    \n",
    "    val_loss_add = 0\n",
    "    for i, data in enumerate(val_loader):\n",
    "            \n",
    "        x, t = data\n",
    "        \n",
    "        #GPU環境で動かす際は，下記2行のコメントを外す\n",
    "        x = x.to(\"cuda\")\n",
    "        t = t.to(\"cuda\")\n",
    "        \n",
    "        predict = model(x) # 順伝播計算\n",
    "        \n",
    "        loss = criterion(predict, t) # 誤差の計算\n",
    "        val_loss_add += loss.data\n",
    "        \n",
    "    val_loss_mean = val_loss_add / int(len(mnist_small_val)/val_loader.batch_size)\n",
    "    print(\"val_loss:\" + str(val_loss_mean))\n",
    "    val_loss_list.append(val_loss_mean.cpu())\n",
    "    \n",
    "    if val_loss_mean < loss_min: # 前に保存したモデルよりもvalidation lossが小さければ，モデルを保存する\n",
    "        torch.save(model.state_dict(), \"/takaya_workspace/self_study/deep_learning/federated_learning/models/best.model\")\n",
    "        print(\"saved best model!\")\n",
    "        loss_min = val_loss_mean # 今回保存したモデルのvalidation lossをメモしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "af76c048-681a-4bf5-a913-10e7b9117295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f594d294d90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss_list, label=\"train\") # train時のlossをplot\n",
    "plt.plot(val_loss_list, label=\"val\") # validation時のlossをplot\n",
    "plt.xlabel(\"epoch\") # X軸のラベルを設定\n",
    "plt.ylabel(\"loss\") # Y軸のラベルを設定\n",
    "plt.legend() # 凡例を追加（plot時に指定したlabelが使われる）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "14534238-4679-4a2b-bba7-8059cbbb3468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_764/3254277216.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7062\n"
     ]
    }
   ],
   "source": [
    "model = MLP() # テストに使うためのMLPを改めて定義\n",
    "\n",
    "#GPU環境で動かす際は，下記のコメントを外す\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "# 学習時に保存しておいたモデルのパラメータをコピー\n",
    "model_path = \"/takaya_workspace/self_study/deep_learning/federated_learning/models/best.model\"\n",
    "model.load_state_dict(torch.load(model_path)) \n",
    "\n",
    "model.eval() # 評価モードであることを明示\n",
    "\n",
    "acc_count = 0 # 正解した数をカウントしておくための変数\n",
    "\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    \n",
    "    x, t = data\n",
    "    \n",
    "    #GPU環境で動かす際は，下記2行のコメントを外す\n",
    "    x = x.to(\"cuda\")\n",
    "    t = t.to(\"cuda\")\n",
    "        \n",
    "    predict = model(x) # 学習済みMLPによる推論\n",
    "    \n",
    "    acc_count += (predict.argmax(axis=1) == t).sum().item()\n",
    "\n",
    "print(\"Test Accuracy: \" + str(acc_count / len(mnist_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ab9215-f979-49b5-ba3a-8131c019521d",
   "metadata": {},
   "source": [
    "だいたい7割弱程度の正解率となったでしょうか？\\\n",
    "それでは，10箇所で100サンプルずつデータを集めることができたと想定して，連合学習を行ってみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3895322d-3c43-4fe8-85a7-f1fff1e416b7",
   "metadata": {},
   "source": [
    "## 連合学習の実装\n",
    "連合学習とは，下図のようにお互いにデータを見せずに，モデルだけを持ち寄って統合する学習方式でした．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e047d7-f40c-48ec-8d81-c7a7a0cea374",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "<IMG SRC=\"https://drive.google.com/uc?id=1zg1JWRJRDzUCIveYfnfSz8SS8-2vBatF\" width=\"70%\"> \n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52eb76-2189-4bc2-82d1-68633db89049",
   "metadata": {},
   "source": [
    "モデルの統合方法は様々ですが，今回は最も単純な方法を試してみましょう．\\\n",
    "\n",
    "流れは次のようになります．\\\n",
    "①統合モデル（global model）を初期化する\n",
    "\n",
    "②各施設へglobal modelを配布する\\\n",
    "③各施設は，自施設のデータを使ってglobal modelをFine Tuning（上書きで学習）する\\\n",
    "④各施設でFine Tuningされたモデル（local model）のパラメータを平均する\\\n",
    "⑤パラメータが平均されたモデルをglobal modelとして保存する\n",
    "\n",
    "②~⑤を1 epoch毎に繰り返し，global modelを更新する．\n",
    "\n",
    "⑥testデータでglobal modelを評価する\n",
    "\n",
    "以上の流れを実現するために，4つの関数を用意します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3716c6a8-904a-4ab1-a199-ca4103263d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_initialize():\n",
    "    init_model = MLP()\n",
    "    torch.save(init_model.state_dict(), \"/takaya_workspace/self_study/deep_learning/federated_learning/models/global.model\")\n",
    "\n",
    "def local_train(hospital_name):\n",
    "    # global_modelを受け取り自施設のデータで訓練し，学習済みモデルをmodel_dirに保存する\n",
    "    dataset = dataset_dir[hospital_name]\n",
    "    n_samples = len(dataset) \n",
    "    train_size = int(n_samples * 0.8) \n",
    "    val_size = n_samples - train_size \n",
    "\n",
    "    train, val = torch.utils.data.random_split(mnist_small, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=10, shuffle=True)\n",
    "    val_loader = DataLoader(val, batch_size=10, shuffle=False)\n",
    "    \n",
    "    # global_modelからパラメータをコピー\n",
    "    local_model = MLP()\n",
    "    global_model_path = \"/takaya_workspace/self_study/deep_learning/federated_learning/models/global.model\"\n",
    "    local_model.load_state_dict(torch.load(global_model_path)) # 学習時に保存しておいたモデルのパラメータをコピー\n",
    "\n",
    "    # GPUを使う場合は，下記のコメントを外す\n",
    "    local_model = local_model.to(\"cuda\")\n",
    "\n",
    "    # optimizer（勾配降下法のアルゴリズム）の準備\n",
    "    optimizer = optim.Adam(local_model.parameters())\n",
    "\n",
    "    # 学習ループ\n",
    "    epochs = 1 #ミニバッチのサンプリングが一巡 = 1 epoch\n",
    "\n",
    "    train_loss_list = [] # epoch毎のtrain_lossを保存しておくための入れ物\n",
    "    val_loss_list = [] # epoch毎のvalidation_lossを保存しておくための入れ物\n",
    "\n",
    "    # ここからループ開始\n",
    "    print(hospital_name + \" training start!\")\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train_loss_add = 0 # 1エポック分の誤差を累積しておくための変数\n",
    "\n",
    "        local_model.train() #学習モードであることを明示\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "\n",
    "            x, t = data # ①データの読み込み\n",
    "\n",
    "            #GPU環境で動かす際は，下記2行のコメントを外す\n",
    "            x = x.to(\"cuda\")\n",
    "            t = t.to(\"cuda\")\n",
    "\n",
    "            predict = local_model(x) # ②順伝播計算\n",
    "\n",
    "            loss = criterion(predict, t) # ③誤差の計算\n",
    "\n",
    "            local_model.zero_grad()# 誤差逆伝播法のための準備\n",
    "            loss.backward() # ④誤差逆伝播法による誤差の計算\n",
    "\n",
    "            optimizer.step() # ⑤勾配を用いてパラメータを更新\n",
    "\n",
    "            train_loss_add += loss.data # あとで平均を計算するために，誤差を累積しておく\n",
    "\n",
    "        train_loss_mean = train_loss_add / int(len(mnist_small_train)/train_loader.batch_size) # 1epochでの誤差の平均を計算\n",
    "        print(\"train_loss:\" + str(train_loss_mean))\n",
    "        train_loss_list.append(train_loss_mean.cpu())# 1epoch毎の平均を格納しておく\n",
    "\n",
    "        # validation\n",
    "        local_model.eval() # 評価モード（学習を行わない）であることを明示\n",
    "\n",
    "        val_loss_add = 0\n",
    "        for i, data in enumerate(val_loader):\n",
    "\n",
    "            x, t = data\n",
    "\n",
    "            #GPU環境で動かす際は，下記2行のコメントを外す\n",
    "            x = x.to(\"cuda\")\n",
    "            t = t.to(\"cuda\")\n",
    "\n",
    "            predict = local_model(x) # 順伝播計算\n",
    "\n",
    "            loss = criterion(predict, t) # 誤差の計算\n",
    "            val_loss_add += loss.data\n",
    "\n",
    "        val_loss_mean = val_loss_add / int(len(mnist_small_val)/val_loader.batch_size)\n",
    "        print(\"val_loss:\" + str(val_loss_mean))\n",
    "        val_loss_list.append(val_loss_mean.cpu())\n",
    "\n",
    "        print(\"saved local model!\")\n",
    "    \n",
    "    # model_dirに学習済みモデルを上書き\n",
    "    local_model = local_model.to(\"cpu\")\n",
    "    model_dir[hospital_name] = local_model\n",
    "    return\n",
    "\n",
    "def model_average():\n",
    "    # model_dirに保存されている各施設のパラメータを平均し，global_modelを更新する\n",
    "    \n",
    "    # パラメータを平均するために，各層のパラメータと同じ形状のゼロ行列を生成\n",
    "    model = MLP() # 仮に定義しておくモデル\n",
    "    \n",
    "    fc1_mean_weight = torch.zeros(size=model.fc1.weight.shape)\n",
    "    fc1_mean_bias = torch.zeros(size=model.fc1.bias.shape)\n",
    "    \n",
    "    fc2_mean_weight = torch.zeros(size=model.fc2.weight.shape)\n",
    "    fc2_mean_bias = torch.zeros(size=model.fc2.bias.shape)\n",
    "    \n",
    "    # model_dirに保存されているパラメータを1つずつ読み込んで足し合わせる\n",
    "    hospital_names = list(model_dir.keys())\n",
    "    for hospital in hospital_names:\n",
    "        fc1_mean_weight += model_dir[hospital].fc1.weight\n",
    "        fc1_mean_bias += model_dir[hospital].fc1.bias\n",
    "        fc2_mean_weight += model_dir[hospital].fc2.weight\n",
    "        fc2_mean_bias += model_dir[hospital].fc2.bias\n",
    "    \n",
    "    # 各パラメータを施設数で割る\n",
    "    fc1_mean_weight  = fc1_mean_weight / len(hospital_names)\n",
    "    fc1_mean_bias = fc1_mean_bias / len(hospital_names)\n",
    "    fc2_mean_weight = fc2_mean_weight / len(hospital_names)\n",
    "    fc2_mean_bias = fc2_mean_bias / len(hospital_names)\n",
    "        \n",
    "    # パラメータの平均をglobal_modelとして保存\n",
    "    global_model = MLP()\n",
    "    global_model.fc1.weight = torch.nn.Parameter(fc1_mean_weight)\n",
    "    global_model.fc1.bias = torch.nn.Parameter(fc1_mean_bias)\n",
    "    global_model.fc2.weight = torch.nn.Parameter(fc2_mean_weight)\n",
    "    global_model.fc2.bias = torch.nn.Parameter(fc2_mean_bias)\n",
    "    \n",
    "    torch.save(global_model.state_dict(), \"/takaya_workspace/self_study/deep_learning/federated_learning/models/global.model\")\n",
    "    print(\"saved global model!\")\n",
    "    return\n",
    "\n",
    "def global_test():\n",
    "    # global_modelの精度をtestデータで評価する\n",
    "    model = MLP() # テストに使うためのMLPを改めて定義\n",
    "\n",
    "    #GPU環境で動かす際は，下記のコメントを外す\n",
    "    model = model.to(\"cuda\")\n",
    "    \n",
    "    # 学習時に保存しておいたモデルのパラメータをコピー\n",
    "    model_path = \"/takaya_workspace/self_study/deep_learning/federated_learning/models/global.model\"\n",
    "    model.load_state_dict(torch.load(model_path)) \n",
    "    \n",
    "    model.eval() # 評価モードであることを明示\n",
    "\n",
    "    acc_count = 0 # 正解した数をカウントしておくための変数\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "\n",
    "        x, t = data\n",
    "        \n",
    "        #GPU環境で動かす際は，下記2行のコメントを外す\n",
    "        x = x.to(\"cuda\")\n",
    "        t = t.to(\"cuda\")\n",
    "\n",
    "        predict = model(x) # グローバルモデルによる推論\n",
    "\n",
    "        acc_count += (predict.argmax(axis=1) == t).sum().item()\n",
    "\n",
    "    print(\"Test Accuracy: \" + str(acc_count / len(mnist_test)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c29a2fb8-889d-4754-9db4-b337e8f51331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(2.2860, device='cuda:0')\n",
      "val_loss:tensor(2.1958, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(2.2573, device='cuda:0')\n",
      "val_loss:tensor(2.2225, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(2.2893, device='cuda:0')\n",
      "val_loss:tensor(2.1917, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_764/3254277216.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:tensor(2.2716, device='cuda:0')\n",
      "val_loss:tensor(2.1685, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(2.2752, device='cuda:0')\n",
      "val_loss:tensor(2.2507, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(2.2837, device='cuda:0')\n",
      "val_loss:tensor(2.2287, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(2.2518, device='cuda:0')\n",
      "val_loss:tensor(2.2969, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(2.2645, device='cuda:0')\n",
      "val_loss:tensor(2.1677, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(2.2805, device='cuda:0')\n",
      "val_loss:tensor(2.2770, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(2.2576, device='cuda:0')\n",
      "val_loss:tensor(2.2581, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 2\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(2.1468, device='cuda:0')\n",
      "val_loss:tensor(2.0623, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(2.1655, device='cuda:0')\n",
      "val_loss:tensor(1.9987, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(2.1538, device='cuda:0')\n",
      "val_loss:tensor(1.9918, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(2.1453, device='cuda:0')\n",
      "val_loss:tensor(2.1602, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(2.1155, device='cuda:0')\n",
      "val_loss:tensor(2.1233, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(2.1511, device='cuda:0')\n",
      "val_loss:tensor(1.9825, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(2.0911, device='cuda:0')\n",
      "val_loss:tensor(2.1612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(2.1269, device='cuda:0')\n",
      "val_loss:tensor(2.0247, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(2.1372, device='cuda:0')\n",
      "val_loss:tensor(2.0223, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(2.1147, device='cuda:0')\n",
      "val_loss:tensor(2.0954, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 3\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.9678, device='cuda:0')\n",
      "val_loss:tensor(1.9565, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.9780, device='cuda:0')\n",
      "val_loss:tensor(2.0346, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.9907, device='cuda:0')\n",
      "val_loss:tensor(1.9305, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.9644, device='cuda:0')\n",
      "val_loss:tensor(1.9875, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.9928, device='cuda:0')\n",
      "val_loss:tensor(1.9111, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.9665, device='cuda:0')\n",
      "val_loss:tensor(2.0305, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.9637, device='cuda:0')\n",
      "val_loss:tensor(2.0248, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.9919, device='cuda:0')\n",
      "val_loss:tensor(1.8481, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.9978, device='cuda:0')\n",
      "val_loss:tensor(1.9622, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.9455, device='cuda:0')\n",
      "val_loss:tensor(2.0243, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 4\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.8343, device='cuda:0')\n",
      "val_loss:tensor(1.8984, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.8757, device='cuda:0')\n",
      "val_loss:tensor(1.7904, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.8744, device='cuda:0')\n",
      "val_loss:tensor(1.8422, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.8711, device='cuda:0')\n",
      "val_loss:tensor(1.7875, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.8663, device='cuda:0')\n",
      "val_loss:tensor(1.8188, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.8556, device='cuda:0')\n",
      "val_loss:tensor(1.7773, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.8249, device='cuda:0')\n",
      "val_loss:tensor(1.9866, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.8356, device='cuda:0')\n",
      "val_loss:tensor(1.8435, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.8377, device='cuda:0')\n",
      "val_loss:tensor(1.9285, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.8604, device='cuda:0')\n",
      "val_loss:tensor(1.8560, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 5\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.7581, device='cuda:0')\n",
      "val_loss:tensor(1.7548, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.7783, device='cuda:0')\n",
      "val_loss:tensor(1.7693, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.7578, device='cuda:0')\n",
      "val_loss:tensor(1.7998, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.7645, device='cuda:0')\n",
      "val_loss:tensor(1.7581, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.7787, device='cuda:0')\n",
      "val_loss:tensor(1.7012, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.7884, device='cuda:0')\n",
      "val_loss:tensor(1.6854, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.7374, device='cuda:0')\n",
      "val_loss:tensor(1.7984, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.7884, device='cuda:0')\n",
      "val_loss:tensor(1.6953, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.7760, device='cuda:0')\n",
      "val_loss:tensor(1.7450, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.7336, device='cuda:0')\n",
      "val_loss:tensor(1.8476, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 6\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.6994, device='cuda:0')\n",
      "val_loss:tensor(1.6058, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.6992, device='cuda:0')\n",
      "val_loss:tensor(1.7071, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.6919, device='cuda:0')\n",
      "val_loss:tensor(1.7308, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.6985, device='cuda:0')\n",
      "val_loss:tensor(1.6856, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.7106, device='cuda:0')\n",
      "val_loss:tensor(1.6644, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.6552, device='cuda:0')\n",
      "val_loss:tensor(1.8272, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.7126, device='cuda:0')\n",
      "val_loss:tensor(1.7706, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.7100, device='cuda:0')\n",
      "val_loss:tensor(1.5937, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.7057, device='cuda:0')\n",
      "val_loss:tensor(1.6903, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.6835, device='cuda:0')\n",
      "val_loss:tensor(1.7897, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 7\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.6390, device='cuda:0')\n",
      "val_loss:tensor(1.6762, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.6585, device='cuda:0')\n",
      "val_loss:tensor(1.6526, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.6540, device='cuda:0')\n",
      "val_loss:tensor(1.5948, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.6587, device='cuda:0')\n",
      "val_loss:tensor(1.7264, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.6336, device='cuda:0')\n",
      "val_loss:tensor(1.7162, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.6651, device='cuda:0')\n",
      "val_loss:tensor(1.6327, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.6323, device='cuda:0')\n",
      "val_loss:tensor(1.7148, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.6632, device='cuda:0')\n",
      "val_loss:tensor(1.6278, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.6756, device='cuda:0')\n",
      "val_loss:tensor(1.5821, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.6482, device='cuda:0')\n",
      "val_loss:tensor(1.6718, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 8\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.6214, device='cuda:0')\n",
      "val_loss:tensor(1.6114, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.6066, device='cuda:0')\n",
      "val_loss:tensor(1.6928, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.6278, device='cuda:0')\n",
      "val_loss:tensor(1.5597, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.5987, device='cuda:0')\n",
      "val_loss:tensor(1.6715, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.6553, device='cuda:0')\n",
      "val_loss:tensor(1.5850, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.6027, device='cuda:0')\n",
      "val_loss:tensor(1.7250, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.5913, device='cuda:0')\n",
      "val_loss:tensor(1.7036, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.6013, device='cuda:0')\n",
      "val_loss:tensor(1.6761, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.5964, device='cuda:0')\n",
      "val_loss:tensor(1.6322, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.6310, device='cuda:0')\n",
      "val_loss:tensor(1.5954, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 9\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.5853, device='cuda:0')\n",
      "val_loss:tensor(1.5954, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.5962, device='cuda:0')\n",
      "val_loss:tensor(1.5174, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.5784, device='cuda:0')\n",
      "val_loss:tensor(1.6297, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.5632, device='cuda:0')\n",
      "val_loss:tensor(1.6911, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.5894, device='cuda:0')\n",
      "val_loss:tensor(1.5634, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.6080, device='cuda:0')\n",
      "val_loss:tensor(1.5391, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.5945, device='cuda:0')\n",
      "val_loss:tensor(1.5607, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.5799, device='cuda:0')\n",
      "val_loss:tensor(1.6257, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.6013, device='cuda:0')\n",
      "val_loss:tensor(1.5369, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.5812, device='cuda:0')\n",
      "val_loss:tensor(1.5925, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 10\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.5575, device='cuda:0')\n",
      "val_loss:tensor(1.5787, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.5442, device='cuda:0')\n",
      "val_loss:tensor(1.6628, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.5555, device='cuda:0')\n",
      "val_loss:tensor(1.6180, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.5774, device='cuda:0')\n",
      "val_loss:tensor(1.5361, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.5652, device='cuda:0')\n",
      "val_loss:tensor(1.5942, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.5859, device='cuda:0')\n",
      "val_loss:tensor(1.4845, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.5948, device='cuda:0')\n",
      "val_loss:tensor(1.4787, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.5779, device='cuda:0')\n",
      "val_loss:tensor(1.5246, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.5618, device='cuda:0')\n",
      "val_loss:tensor(1.5888, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.5518, device='cuda:0')\n",
      "val_loss:tensor(1.6077, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 11\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.5722, device='cuda:0')\n",
      "val_loss:tensor(1.5052, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.5464, device='cuda:0')\n",
      "val_loss:tensor(1.6745, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.5601, device='cuda:0')\n",
      "val_loss:tensor(1.5546, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.5775, device='cuda:0')\n",
      "val_loss:tensor(1.4627, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.5348, device='cuda:0')\n",
      "val_loss:tensor(1.6290, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.5586, device='cuda:0')\n",
      "val_loss:tensor(1.5311, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.5357, device='cuda:0')\n",
      "val_loss:tensor(1.6203, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.5483, device='cuda:0')\n",
      "val_loss:tensor(1.5597, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.5591, device='cuda:0')\n",
      "val_loss:tensor(1.5392, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.5505, device='cuda:0')\n",
      "val_loss:tensor(1.6433, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 12\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.5056, device='cuda:0')\n",
      "val_loss:tensor(1.6918, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.5337, device='cuda:0')\n",
      "val_loss:tensor(1.5740, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.5294, device='cuda:0')\n",
      "val_loss:tensor(1.6173, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.5240, device='cuda:0')\n",
      "val_loss:tensor(1.5621, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.5371, device='cuda:0')\n",
      "val_loss:tensor(1.5568, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.5603, device='cuda:0')\n",
      "val_loss:tensor(1.4699, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.5297, device='cuda:0')\n",
      "val_loss:tensor(1.5962, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.5356, device='cuda:0')\n",
      "val_loss:tensor(1.5839, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.5397, device='cuda:0')\n",
      "val_loss:tensor(1.5816, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.5381, device='cuda:0')\n",
      "val_loss:tensor(1.5302, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 13\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.5163, device='cuda:0')\n",
      "val_loss:tensor(1.5167, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.5189, device='cuda:0')\n",
      "val_loss:tensor(1.5541, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.5213, device='cuda:0')\n",
      "val_loss:tensor(1.5353, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.5144, device='cuda:0')\n",
      "val_loss:tensor(1.5081, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.5277, device='cuda:0')\n",
      "val_loss:tensor(1.4745, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.5214, device='cuda:0')\n",
      "val_loss:tensor(1.4930, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.5211, device='cuda:0')\n",
      "val_loss:tensor(1.5828, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.5343, device='cuda:0')\n",
      "val_loss:tensor(1.4686, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.5180, device='cuda:0')\n",
      "val_loss:tensor(1.5470, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.5211, device='cuda:0')\n",
      "val_loss:tensor(1.4860, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 14\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.5072, device='cuda:0')\n",
      "val_loss:tensor(1.4751, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.5450, device='cuda:0')\n",
      "val_loss:tensor(1.5334, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.5039, device='cuda:0')\n",
      "val_loss:tensor(1.5100, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4929, device='cuda:0')\n",
      "val_loss:tensor(1.5251, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4974, device='cuda:0')\n",
      "val_loss:tensor(1.5339, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4997, device='cuda:0')\n",
      "val_loss:tensor(1.5161, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.5026, device='cuda:0')\n",
      "val_loss:tensor(1.4699, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.5133, device='cuda:0')\n",
      "val_loss:tensor(1.4642, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4940, device='cuda:0')\n",
      "val_loss:tensor(1.6207, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.5053, device='cuda:0')\n",
      "val_loss:tensor(1.4889, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 15\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4737, device='cuda:0')\n",
      "val_loss:tensor(1.5334, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4781, device='cuda:0')\n",
      "val_loss:tensor(1.5161, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4884, device='cuda:0')\n",
      "val_loss:tensor(1.4712, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4922, device='cuda:0')\n",
      "val_loss:tensor(1.4743, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4911, device='cuda:0')\n",
      "val_loss:tensor(1.4937, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4879, device='cuda:0')\n",
      "val_loss:tensor(1.4816, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4875, device='cuda:0')\n",
      "val_loss:tensor(1.4984, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4803, device='cuda:0')\n",
      "val_loss:tensor(1.5025, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4807, device='cuda:0')\n",
      "val_loss:tensor(1.5136, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4833, device='cuda:0')\n",
      "val_loss:tensor(1.5013, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 16\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4915, device='cuda:0')\n",
      "val_loss:tensor(1.4833, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4862, device='cuda:0')\n",
      "val_loss:tensor(1.4805, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4767, device='cuda:0')\n",
      "val_loss:tensor(1.5189, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4853, device='cuda:0')\n",
      "val_loss:tensor(1.4650, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4857, device='cuda:0')\n",
      "val_loss:tensor(1.4719, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4766, device='cuda:0')\n",
      "val_loss:tensor(1.5019, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4908, device='cuda:0')\n",
      "val_loss:tensor(1.4630, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4917, device='cuda:0')\n",
      "val_loss:tensor(1.5184, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4794, device='cuda:0')\n",
      "val_loss:tensor(1.5154, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4776, device='cuda:0')\n",
      "val_loss:tensor(1.5005, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 17\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4747, device='cuda:0')\n",
      "val_loss:tensor(1.4839, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4827, device='cuda:0')\n",
      "val_loss:tensor(1.4887, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4815, device='cuda:0')\n",
      "val_loss:tensor(1.4641, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4753, device='cuda:0')\n",
      "val_loss:tensor(1.4799, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4705, device='cuda:0')\n",
      "val_loss:tensor(1.5144, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4670, device='cuda:0')\n",
      "val_loss:tensor(1.5114, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4675, device='cuda:0')\n",
      "val_loss:tensor(1.5193, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4736, device='cuda:0')\n",
      "val_loss:tensor(1.4703, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4766, device='cuda:0')\n",
      "val_loss:tensor(1.4839, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4770, device='cuda:0')\n",
      "val_loss:tensor(1.4747, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 18\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4701, device='cuda:0')\n",
      "val_loss:tensor(1.4952, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4663, device='cuda:0')\n",
      "val_loss:tensor(1.4683, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4889, device='cuda:0')\n",
      "val_loss:tensor(1.4618, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4657, device='cuda:0')\n",
      "val_loss:tensor(1.4658, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4786, device='cuda:0')\n",
      "val_loss:tensor(1.4715, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4681, device='cuda:0')\n",
      "val_loss:tensor(1.4623, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4754, device='cuda:0')\n",
      "val_loss:tensor(1.4615, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4834, device='cuda:0')\n",
      "val_loss:tensor(1.4644, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4729, device='cuda:0')\n",
      "val_loss:tensor(1.4790, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4665, device='cuda:0')\n",
      "val_loss:tensor(1.4662, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 19\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4629, device='cuda:0')\n",
      "val_loss:tensor(1.4790, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4666, device='cuda:0')\n",
      "val_loss:tensor(1.5074, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4702, device='cuda:0')\n",
      "val_loss:tensor(1.4748, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4641, device='cuda:0')\n",
      "val_loss:tensor(1.4633, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4640, device='cuda:0')\n",
      "val_loss:tensor(1.4632, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4819, device='cuda:0')\n",
      "val_loss:tensor(1.4684, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4716, device='cuda:0')\n",
      "val_loss:tensor(1.4615, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4670, device='cuda:0')\n",
      "val_loss:tensor(1.4822, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4738, device='cuda:0')\n",
      "val_loss:tensor(1.4665, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4629, device='cuda:0')\n",
      "val_loss:tensor(1.4661, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 20\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4685, device='cuda:0')\n",
      "val_loss:tensor(1.4620, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4634, device='cuda:0')\n",
      "val_loss:tensor(1.4622, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4631, device='cuda:0')\n",
      "val_loss:tensor(1.4710, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4626, device='cuda:0')\n",
      "val_loss:tensor(1.4701, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4742, device='cuda:0')\n",
      "val_loss:tensor(1.4615, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4657, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4642, device='cuda:0')\n",
      "val_loss:tensor(1.4670, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4626, device='cuda:0')\n",
      "val_loss:tensor(1.4620, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4698, device='cuda:0')\n",
      "val_loss:tensor(1.4613, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4620, device='cuda:0')\n",
      "val_loss:tensor(1.4668, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 21\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4697, device='cuda:0')\n",
      "val_loss:tensor(1.4615, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4672, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4623, device='cuda:0')\n",
      "val_loss:tensor(1.4630, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4627, device='cuda:0')\n",
      "val_loss:tensor(1.4652, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4631, device='cuda:0')\n",
      "val_loss:tensor(1.4622, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4645, device='cuda:0')\n",
      "val_loss:tensor(1.4690, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4738, device='cuda:0')\n",
      "val_loss:tensor(1.4626, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4697, device='cuda:0')\n",
      "val_loss:tensor(1.4615, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4631, device='cuda:0')\n",
      "val_loss:tensor(1.4620, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4619, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 22\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4631, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4643, device='cuda:0')\n",
      "val_loss:tensor(1.4618, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4618, device='cuda:0')\n",
      "val_loss:tensor(1.4619, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4622, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4646, device='cuda:0')\n",
      "val_loss:tensor(1.4620, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4616, device='cuda:0')\n",
      "val_loss:tensor(1.4615, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4622, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4630, device='cuda:0')\n",
      "val_loss:tensor(1.4626, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4618, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4617, device='cuda:0')\n",
      "val_loss:tensor(1.4616, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 23\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4614, device='cuda:0')\n",
      "val_loss:tensor(1.4617, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4616, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4620, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4614, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4615, device='cuda:0')\n",
      "val_loss:tensor(1.4642, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4614, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4629, device='cuda:0')\n",
      "val_loss:tensor(1.4615, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4615, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 24\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4614, device='cuda:0')\n",
      "val_loss:tensor(1.4613, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4619, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4667, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4614, device='cuda:0')\n",
      "val_loss:tensor(1.4619, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4618, device='cuda:0')\n",
      "val_loss:tensor(1.4615, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4620, device='cuda:0')\n",
      "val_loss:tensor(1.4613, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4617, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4613, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4613, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 25\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4613, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4613, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4619, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4614, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 26\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4618, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4615, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 27\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 28\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4613, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4613, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 29\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "epoch 30\n",
      "Hospital_1 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_2 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_3 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_4 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_5 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_6 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_7 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_8 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_9 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "Hospital_10 training start!\n",
      "train_loss:tensor(1.4612, device='cuda:0')\n",
      "val_loss:tensor(1.4612, device='cuda:0')\n",
      "saved local model!\n",
      "saved global model!\n",
      "Test Accuracy: 0.751\n"
     ]
    }
   ],
   "source": [
    "# 全施設分のモデルを格納しておくための辞書\n",
    "model_dir = {}\n",
    "\n",
    "# 序盤のセルで作成済みのdataset_dirから，病院名のみを取り出してリスト化\n",
    "hospital_list = list(dataset_dir.keys()) \n",
    "\n",
    "# global modelの初期化 ①\n",
    "model_initialize()\n",
    "\n",
    "epochs = 30 # ②~⑤の繰り返し回数\n",
    "\n",
    "# ②~⑤の繰り返し\n",
    "for i in range(epochs):\n",
    "    print(\"epoch \" + str(i+1))\n",
    "    for hospital in hospital_list:\n",
    "        local_train(hospital) # ②，③\n",
    "    model_average() # ④，⑤\n",
    "\n",
    "# global modelの評価 ⑥\n",
    "global_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02c21b-0c72-4a0d-87da-ee95726146a4",
   "metadata": {},
   "source": [
    "Hospital_1単体でモデルの訓練を行った場合より，Accuracyが上昇しているのが確認できたかと思います．\\\n",
    "施設数を増やした場合や，各施設が持つサンプル数を変化させた場合にはどのような影響があるか，みなさん自身で確かめてみてください！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ee413d-e693-4672-986f-07026d41901f",
   "metadata": {},
   "source": [
    "## 連合学習の課題\n",
    "連合学習を行うことで，複数施設同士でデータをやりとりすることなく，単一施設では実現できないような精度を達成することができました．\\\n",
    "しかし，仮に複数施設で集めたデータを一箇所に集めて学習した場合はどうでしょうか？\\\n",
    "実はその場合，連合学習を行った場合よりも高い精度を達成することができます（今回は確認しませんでしたが，高屋が実験した限りでは，accuracy=0.8を軽く超えます）．\\\n",
    "\n",
    "つまり，連合学習では，1箇所に集めた場合に達成しうる精度へいかに近づくことができるかが課題となります．\\\n",
    "今回実践した方法は最も単純な方法でしたが，現在ではより精度を高めるための手法が次々と出てきているので，興味がある人は調べてみましょう．\\\n",
    "医療AIの国際会議であるMICCAI[リンク]やISBI[リンク]など，医療AIの国際会議などをチェックしてみることをオススメします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d6e12-a130-48ee-8166-1fda9a64004e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
